<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator>
  <link href="/author/shivang.singh/feed.xml" rel="self" type="application/atom+xml" />
  <link href="/" rel="alternate" type="text/html" />
  <updated>2019-04-03T01:49:43+00:00</updated>
  <id>/author/shivang.singh/feed.xml</id>

  
  
  

  
    <title type="html">The Pangean | </title>
  

  
    <subtitle>Taking a step back</subtitle>
  

  

  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
  

  
    <entry>
      <title type="html">Understanding the Great Divergence and the Great Convergence</title>
      <link href="/Understanding-the-Great-Divergence-and-the-Great-Convergence" rel="alternate" type="text/html" title="Understanding the Great Divergence and the Great Convergence" />
      <published>2019-03-15T15:18:00+00:00</published>
      <updated>2019-03-15T15:18:00+00:00</updated>
      <id>/Understanding-the-Great-Divergence-and-the-Great-Convergence</id>
      <content type="html" xml:base="/Understanding-the-Great-Divergence-and-the-Great-Convergence">&lt;p&gt;Prior to the beginning of the 19th century, economies around the world were
highly localised and agrarian. Commerce was seemingly restricted to domestic
production and self-consumption, compelling countries to thrive independently;
transnational trade was underdeveloped at the time. However, with the advent of
the Industrial Revolution in Western Europe around 1760, nations discovered new
methods of production and advanced ways of transportation that employed
inventive machinery and steam power. This facilitated trade by lowering the
costs of moving goods across borders, thus marking the dawn of an age of
globalisation.&lt;/p&gt;

&lt;p&gt;Such an unprecedented change in the environment for trade gave way to what
scholars term the “Great Divergence”. Between 1820 and 1990, the Great
Divergence is said to have sponsored a rise in the share of global income going
to the Western world from one-fifth of the total to an estimated two-thirds.
Conversely, however, today that share has plunged to where it was in 1900, thus
representing what academics have named the “Great Convergence”. Identified with
reduced communication costs in addition to low trade costs, the Great
Convergence has endorsed the rapid growth of developing and underdeveloped
countries, collectively bringing them almost at par with the share of global GDP
going to the Western world today.&lt;/p&gt;

&lt;p&gt;Throughout the history of humankind, there have been three elaborate phases that
have led to the development of today’s global economy. Phase One, which existed
between 200,000 BCE and 10,000 BCE, was predominantly characterised by the
procurement of food over various seasons and regions. The early man moved around
in search of new locations where he could hunt or cultivate. Food was the
primary good of exchange. Hence, this phase was characterised by
self-locomotion, rather than the movement of goods. In Phase Two, the global
economy progressed towards localisation, and witnessed the exchange of diverse
goods and services between 10,000 BCE and 1820 CE. Revolutions in agriculture
and science triggered population growth, which led to the formation of
civilisations and food surpluses.  Countries termed the &lt;em&gt;Ancient Seven&lt;/em&gt; or the
&lt;em&gt;A7&lt;/em&gt; flourished extensively and witnessed sizeable economic growth. These were
India, China, Egypt, Turkey, Iran, Iraq, and Greece/Italy. It was more
profitable for these countries to manufacture and sell within domestic
territories rather than globally. Local market conditions determined prices,
while international factors had almost no role to play. Although trade did
emerge with the development of the Silk Route and Spice Route among other means,
globalisation in its modern understanding had not yet begun on account of high
trade costs, high communication costs, and high face-to-face costs. It was only
after 1820 that Phase Three witnessed true globalisation.  &lt;/p&gt;

&lt;p&gt;Having harnessed steam power, the Industrial Revolution in Western Europe
emphasised the importance of iron and steel in modern manufacturing while
augmenting the establishment of factories and industrial districts. Production
was micro-clustered to gain from economies of scale by channeling
specialisation, division of labour and better allocation of resources. With the
development of railroads and steamships, trade costs dipped, thus enlarging
international trade volumes significantly. Incomes of Western countries
subsequently diverged and marked the beginning of the Great Divergence. Kenneth
Pomeranz’s book, &lt;em&gt;The Great Divergence&lt;/em&gt;, is accredited with making the term
popular among business historians and economists.&lt;/p&gt;

&lt;p&gt;But, why did the incomes of the West and the Rest diverge? Since 1500, India and
China had been enjoying the largest shares of world output with high per capita
incomes and wealthy trade. What caused the sudden divergence of Western incomes
that led to what some have termed the “North-South income gap”? There are three
prominent explanations. The first explanation stresses on &lt;em&gt;cultural factors&lt;/em&gt;.
Niall Ferguson, author of &lt;em&gt;Civilization: West and the Rest&lt;/em&gt;, identifies the
Protestant work ethic as a killer model of capitalist enterprise. The &lt;em&gt;Group of
Seven&lt;/em&gt; or &lt;em&gt;G7&lt;/em&gt; countries: United States, Britain, France, Germany, Canada,
Japan, and Italy, underwent rapid industrialization and overtook the &lt;em&gt;A7&lt;/em&gt; in
world dominance and wealth. The West apparently had the ‘right’ culture while
the Rest had the ‘wrong’ culture for sustenance in the international market post
Phase Three&lt;strong&gt;.&lt;/strong&gt; Unsurprisingly, this explanation is highly contested and lacks
adequate evidence for its validity.&lt;/p&gt;

&lt;p&gt;The second explanation highlights &lt;em&gt;institutional factors&lt;/em&gt;. It is said that the
West had at its disposal, access to better institutions and progressive
political establishments, thus facilitating faster growth in the modern era. On
the contrary, countries like India suffered adverse colonial rule while
countries like China witnessed regular instabilities with changing regimes and
leaders. Similarly, the legal systems in &lt;em&gt;G7&lt;/em&gt; countries were more advanced and
accountable relative to their &lt;em&gt;A7&lt;/em&gt; counterparts. There is sufficient evidence to
back these claims, however, the Great Divergence was not entirely based on the
foundations of this explanation. And reinforcing this criticism, the final
explanation talks about &lt;em&gt;educational factors&lt;/em&gt; as determinants of global wealth
and poverty.  &lt;/p&gt;

&lt;p&gt;As Claudia Goldin claims in the research paper &lt;em&gt;The Human-Capital Century and
American Leadership:&lt;/em&gt; “the unique egalitarian mass provision of post-elementary
schooling achieved in the United States during the early twentieth century”
validates the educational superiority of the West compared to the Rest. Western
Europe and North America witnessed higher literacy rates and more spending on
education in the modern era, thus augmenting their abilities in trade and
commerce.&lt;/p&gt;

&lt;p&gt;I would say that the harmonisation of all these factors can be said to have led
to the Great Divergence. For most of the modern era, the West outshone the Rest
in all three – cultural, institutional, and educational factors. But then, what
really led to the Great Convergence? Was it the West that lost pace or the Rest
that gathered it? Well, both happened simultaneously…&lt;/p&gt;

&lt;p&gt;The growth of the West is said to have slowed down after attaining a certain
degree of development, while growth of the Rest is said to have sped up so as to
attain that certain degree of development. The mutual decrease in trade and
communication costs is what facilitated the Great Convergence. With the advent
of information technology, the cost of moving &lt;em&gt;ideas&lt;/em&gt; across borders, besides
&lt;em&gt;goods&lt;/em&gt;, fell significantly. This made it possible for multinational firms to
shift labour-intensive work to underdeveloped and developing nations, thus
saving private as well as social costs. However, in order to preserve and
maintain the entire production process, in addition to outsourcing jobs, these
firms also had to transfer their technical, managerial, financial, and marketing
know-how to these countries – mainly the currently &lt;em&gt;Industrialising Six&lt;/em&gt; or &lt;em&gt;I6&lt;/em&gt;
– China, India, Poland, Korea, Thailand, and Indonesia.  &lt;/p&gt;

&lt;p&gt;The West aimed at gaining from the unification of advanced technology and
skilled workers, both of which were easily and economically available in these
countries. While this promoted the industrialisation of the &lt;em&gt;I6&lt;/em&gt;, it also
triggered the deindustrialisation of the &lt;em&gt;G7&lt;/em&gt;. Moreover, towards the end of the
20th century, &lt;em&gt;I6&lt;/em&gt; countries began investing considerably in improving their
institutions and extending education to more citizens. Most exploited countries
were no longer under colonial rule; there was more political stability within
nations and greater international peace after the Second World War. These
factors collectively helped developing countries amplify their growth, and
secure higher incomes with better standards of living for their people.
Therefore, investment brought into developing countries by developed ones, and
self-investment by developing countries themselves, are what mutually led to a
decline in the Western share of global GDP and a convergence of income
inequalities between the global North and South. The stagnated and shrunken
economies of China and India, among others, in the &lt;em&gt;I6&lt;/em&gt; revived remarkably.  &lt;/p&gt;

&lt;p&gt;Today, &lt;em&gt;I6&lt;/em&gt; countries and &lt;em&gt;G7&lt;/em&gt; countries enjoy more or less the same share of
global income and output. Although the &lt;em&gt;G7&lt;/em&gt; might still be richer than the
&lt;em&gt;I6&lt;/em&gt;, they no longer treasure the dominance that they once did. Poverty in
developing countries is on the fall owing to an increase in employment and
improved quality of life. Contrastingly, wealth in developed countries is on the
fall owing to debt burdens, reduced employment, brain-drain, and monetary
advances to the rest of the world.  &lt;/p&gt;

&lt;p&gt;We may affirm that the two final phases in the evolution of globalisation were
responsible for both the Great Divergence and the Great Convergence; only these
two phases differed vastly from one another. The former of the two phases
witnessed the growth of the Asian economies until the 19th century, after which
the European-Atlantic Economy surpassed the income levels and growth rates
prevalent in pre-modern Asia. The latter of the two phases is accredited with
subduing the growth of modern European-Atlantic countries, while elevating Asian
ones to better income levels and improved growth rates. This reversed cycle
confirms that both phases of globalisation are opposite to each other in nature.
Currently, we live in its second phase attributed to advanced information
technology and global income parity. And there is no better way to end this
economic-history article than asking, “&lt;em&gt;What Next?”&lt;/em&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Shivang Singh</name>
        
        
      </author>

      

      
        <category term="economics" />
      

      
        <summary type="html">Prior to the beginning of the 19th century, economies around the world were highly localised and agrarian. Commerce was seemingly restricted to domestic production and self-consumption, compelling countries to thrive independently; transnational trade was underdeveloped at the time. However, with the advent of the Industrial Revolution in Western Europe around 1760, nations discovered new methods of production and advanced ways of transportation that employed inventive machinery and steam power. This facilitated trade by lowering the costs of moving goods across borders, thus marking the dawn of an age of globalisation. Such an unprecedented change in the environment for trade gave way to what scholars term the “Great Divergence”. Between 1820 and 1990, the Great Divergence is said to have sponsored a rise in the share of global income going to the Western world from one-fifth of the total to an estimated two-thirds. Conversely, however, today that share has plunged to where it was in 1900, thus representing what academics have named the “Great Convergence”. Identified with reduced communication costs in addition to low trade costs, the Great Convergence has endorsed the rapid growth of developing and underdeveloped countries, collectively bringing them almost at par with the share of global GDP going to the Western world today. Throughout the history of humankind, there have been three elaborate phases that have led to the development of today’s global economy. Phase One, which existed between 200,000 BCE and 10,000 BCE, was predominantly characterised by the procurement of food over various seasons and regions. The early man moved around in search of new locations where he could hunt or cultivate. Food was the primary good of exchange. Hence, this phase was characterised by self-locomotion, rather than the movement of goods. In Phase Two, the global economy progressed towards localisation, and witnessed the exchange of diverse goods and services between 10,000 BCE and 1820 CE. Revolutions in agriculture and science triggered population growth, which led to the formation of civilisations and food surpluses.  Countries termed the Ancient Seven or the A7 flourished extensively and witnessed sizeable economic growth. These were India, China, Egypt, Turkey, Iran, Iraq, and Greece/Italy. It was more profitable for these countries to manufacture and sell within domestic territories rather than globally. Local market conditions determined prices, while international factors had almost no role to play. Although trade did emerge with the development of the Silk Route and Spice Route among other means, globalisation in its modern understanding had not yet begun on account of high trade costs, high communication costs, and high face-to-face costs. It was only after 1820 that Phase Three witnessed true globalisation.   Having harnessed steam power, the Industrial Revolution in Western Europe emphasised the importance of iron and steel in modern manufacturing while augmenting the establishment of factories and industrial districts. Production was micro-clustered to gain from economies of scale by channeling specialisation, division of labour and better allocation of resources. With the development of railroads and steamships, trade costs dipped, thus enlarging international trade volumes significantly. Incomes of Western countries subsequently diverged and marked the beginning of the Great Divergence. Kenneth Pomeranz’s book, The Great Divergence, is accredited with making the term popular among business historians and economists. But, why did the incomes of the West and the Rest diverge? Since 1500, India and China had been enjoying the largest shares of world output with high per capita incomes and wealthy trade. What caused the sudden divergence of Western incomes that led to what some have termed the “North-South income gap”? There are three prominent explanations. The first explanation stresses on cultural factors. Niall Ferguson, author of Civilization: West and the Rest, identifies the Protestant work ethic as a killer model of capitalist enterprise. The Group of Seven or G7 countries: United States, Britain, France, Germany, Canada, Japan, and Italy, underwent rapid industrialization and overtook the A7 in world dominance and wealth. The West apparently had the ‘right’ culture while the Rest had the ‘wrong’ culture for sustenance in the international market post Phase Three. Unsurprisingly, this explanation is highly contested and lacks adequate evidence for its validity. The second explanation highlights institutional factors. It is said that the West had at its disposal, access to better institutions and progressive political establishments, thus facilitating faster growth in the modern era. On the contrary, countries like India suffered adverse colonial rule while countries like China witnessed regular instabilities with changing regimes and leaders. Similarly, the legal systems in G7 countries were more advanced and accountable relative to their A7 counterparts. There is sufficient evidence to back these claims, however, the Great Divergence was not entirely based on the foundations of this explanation. And reinforcing this criticism, the final explanation talks about educational factors as determinants of global wealth and poverty.   As Claudia Goldin claims in the research paper The Human-Capital Century and American Leadership: “the unique egalitarian mass provision of post-elementary schooling achieved in the United States during the early twentieth century” validates the educational superiority of the West compared to the Rest. Western Europe and North America witnessed higher literacy rates and more spending on education in the modern era, thus augmenting their abilities in trade and commerce. I would say that the harmonisation of all these factors can be said to have led to the Great Divergence. For most of the modern era, the West outshone the Rest in all three – cultural, institutional, and educational factors. But then, what really led to the Great Convergence? Was it the West that lost pace or the Rest that gathered it? Well, both happened simultaneously… The growth of the West is said to have slowed down after attaining a certain degree of development, while growth of the Rest is said to have sped up so as to attain that certain degree of development. The mutual decrease in trade and communication costs is what facilitated the Great Convergence. With the advent of information technology, the cost of moving ideas across borders, besides goods, fell significantly. This made it possible for multinational firms to shift labour-intensive work to underdeveloped and developing nations, thus saving private as well as social costs. However, in order to preserve and maintain the entire production process, in addition to outsourcing jobs, these firms also had to transfer their technical, managerial, financial, and marketing know-how to these countries – mainly the currently Industrialising Six or I6 – China, India, Poland, Korea, Thailand, and Indonesia.   The West aimed at gaining from the unification of advanced technology and skilled workers, both of which were easily and economically available in these countries. While this promoted the industrialisation of the I6, it also triggered the deindustrialisation of the G7. Moreover, towards the end of the 20th century, I6 countries began investing considerably in improving their institutions and extending education to more citizens. Most exploited countries were no longer under colonial rule; there was more political stability within nations and greater international peace after the Second World War. These factors collectively helped developing countries amplify their growth, and secure higher incomes with better standards of living for their people. Therefore, investment brought into developing countries by developed ones, and self-investment by developing countries themselves, are what mutually led to a decline in the Western share of global GDP and a convergence of income inequalities between the global North and South. The stagnated and shrunken economies of China and India, among others, in the I6 revived remarkably.   Today, I6 countries and G7 countries enjoy more or less the same share of global income and output. Although the G7 might still be richer than the I6, they no longer treasure the dominance that they once did. Poverty in developing countries is on the fall owing to an increase in employment and improved quality of life. Contrastingly, wealth in developed countries is on the fall owing to debt burdens, reduced employment, brain-drain, and monetary advances to the rest of the world.   We may affirm that the two final phases in the evolution of globalisation were responsible for both the Great Divergence and the Great Convergence; only these two phases differed vastly from one another. The former of the two phases witnessed the growth of the Asian economies until the 19th century, after which the European-Atlantic Economy surpassed the income levels and growth rates prevalent in pre-modern Asia. The latter of the two phases is accredited with subduing the growth of modern European-Atlantic countries, while elevating Asian ones to better income levels and improved growth rates. This reversed cycle confirms that both phases of globalisation are opposite to each other in nature. Currently, we live in its second phase attributed to advanced information technology and global income parity. And there is no better way to end this economic-history article than asking, “What Next?”</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Can Minimum Wage Reduce Poverty?</title>
      <link href="/Can-Minimum-Wage-Reduce-Poverty" rel="alternate" type="text/html" title="Can Minimum Wage Reduce Poverty?" />
      <published>2019-03-08T23:45:00+00:00</published>
      <updated>2019-03-08T23:45:00+00:00</updated>
      <id>/Can-Minimum-Wage-Reduce-Poverty</id>
      <content type="html" xml:base="/Can-Minimum-Wage-Reduce-Poverty">&lt;p&gt;&lt;em&gt;A guide to its effective implementation…&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The minimum wage in the United Kingdom is considered one of the most successful
government policies ever implemented. It was intricately planned and structured
over a significant length of time. And with one of the lowest unemployment rates
in Europe, Britain, at first sight, appears to illustrate an accurate balance
between executing a minimum wage policy and preserving the uniform availability
of job opportunities (even if Brexit could change that drastically). Apart from
Britain, even Hong Kong has witnessed an upward trend in median monthly wages of
unskilled workers by 43% in money terms and 20% in real terms between 2010 and 2014. Synchronously, the 2014 Report on Annual Earnings and Hours Survey
published by The Census and Statistics Department outlines inputs from the
Minimum Wage Commission that indicate a fall in the unemployment rate for
elementary occupations from 4.4% in 2010 to 3.3% in 2014. Advocates of minimum
wage legislation argue that it can alter the income distribution in favour of
the low-paid labour force by attenuating the bottom tail of the distribution
model. Opponents criticise its “Disemployment Effect” and emphasise that it
might shrink the share of earnings going to the impoverished and destitute
workforce.&lt;/p&gt;

&lt;p&gt;A higher minimum wage, evidently, increases costs for firms. This may curtail
them from hiring the exceptionally low-wage, low-skill workers. David Neumark,
an American labour economist, terms this the “Disemployment Effect”. It is
characterised by the loss of jobs, reduction in working hours, automation, or
the struggle to enter into new jobs. The Disemployment Effect, if necessitated
by a minimum wage, invalidates the purpose of bringing in such a policy in the
first place. But this effect can be overcome. Firms can be offered economic
incentives such as subsidies and grants, to compensate for their increased
costs. Lower taxes and excise duties could also serve as economic incentives,
ensuring more cash is available for businesses to absorb the costs of paying a
higher minimum wage.&lt;/p&gt;

&lt;p&gt;However, the Disemployment Effect is not the only uncertain outcome of a minimum
wage policy, especially in developing countries. As the minimum wage and poverty
lines are closer to each other in developing nations, an increase in minimum
wage could lift workers out of destitution. Yet, several minimum wage workers in
developing countries are young, work part-time, and belong to high-income
households. Correspondingly, most households in poverty seldom have anyone in
the workforce&lt;strong&gt;.&lt;/strong&gt; Hence, more often than not, a minimum wage ends up helping
the privileged and ignoring the needy.&lt;/p&gt;

&lt;p&gt;To end poverty, a minimum wage should be determined for households and not
individuals. This will facilitate the redistribution of income to poor families
over low-earners of rich families. Simultaneously, governments must increase
spending on education and skill development to build an economy with a speedily
employable workforce, hence fostering growth and development. A minimum wage
policy also needs to tackle the problem of incomplete and irregular legal
coverage. Although minimum wages seem to be extensively applicable, in several
cases the coverage is ineffective and disregards those most in need of social
security, such as domestic workers or homeworkers. By neglecting a few crucial
sectors of the economy, we fail to fully utilise the potential of minimum wage
legislation. Even though legal coverage of the minimum wage developed from the
mid-2000’s to the late 2000’s in India and South Africa, it covered only about
70% of low-paid workers by late 2000’s; in Peru, domestic workers were barred
from the statutory minimum wage&lt;strong&gt;.&lt;/strong&gt; Research suggests that weak legal coverage
may at times ignore around one-third of all wage earners.&lt;/p&gt;

&lt;p&gt;We may confront this perplexity by undertaking comprehensive legislation that
gratifies all sectors of an economy, and by ensuring that such legislation is
strictly enforced. This, while a herculean task, can be accomplished by the
extensive and intensive consultation of all stakeholders and a thorough analysis
of a variety of socioeconomic and employment data.&lt;/p&gt;

&lt;p&gt;The minimum wage is fast becoming a universally adopted policy today and the
principal question is how to operate the system in order to maximise its
benefits. A conscientiously devised minimum wage policy can relegate low pay,
inequalities, and poverty, at little or no adverse cost to employment. Yet, the
minimum wage either continues to be low in many countries, or applies solely to
certain select sectors. But with a little more fine-tuning, as I have suggested,
I believe it is possible to shape an effective minimum wage policy that
successfully reduces poverty and income inequalities across countries without
hurting the job market.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Shivang Singh</name>
        
        
      </author>

      

      
        <category term="economics" />
      

      
        <summary type="html">A guide to its effective implementation… The minimum wage in the United Kingdom is considered one of the most successful government policies ever implemented. It was intricately planned and structured over a significant length of time. And with one of the lowest unemployment rates in Europe, Britain, at first sight, appears to illustrate an accurate balance between executing a minimum wage policy and preserving the uniform availability of job opportunities (even if Brexit could change that drastically). Apart from Britain, even Hong Kong has witnessed an upward trend in median monthly wages of unskilled workers by 43% in money terms and 20% in real terms between 2010 and 2014. Synchronously, the 2014 Report on Annual Earnings and Hours Survey published by The Census and Statistics Department outlines inputs from the Minimum Wage Commission that indicate a fall in the unemployment rate for elementary occupations from 4.4% in 2010 to 3.3% in 2014. Advocates of minimum wage legislation argue that it can alter the income distribution in favour of the low-paid labour force by attenuating the bottom tail of the distribution model. Opponents criticise its “Disemployment Effect” and emphasise that it might shrink the share of earnings going to the impoverished and destitute workforce. A higher minimum wage, evidently, increases costs for firms. This may curtail them from hiring the exceptionally low-wage, low-skill workers. David Neumark, an American labour economist, terms this the “Disemployment Effect”. It is characterised by the loss of jobs, reduction in working hours, automation, or the struggle to enter into new jobs. The Disemployment Effect, if necessitated by a minimum wage, invalidates the purpose of bringing in such a policy in the first place. But this effect can be overcome. Firms can be offered economic incentives such as subsidies and grants, to compensate for their increased costs. Lower taxes and excise duties could also serve as economic incentives, ensuring more cash is available for businesses to absorb the costs of paying a higher minimum wage. However, the Disemployment Effect is not the only uncertain outcome of a minimum wage policy, especially in developing countries. As the minimum wage and poverty lines are closer to each other in developing nations, an increase in minimum wage could lift workers out of destitution. Yet, several minimum wage workers in developing countries are young, work part-time, and belong to high-income households. Correspondingly, most households in poverty seldom have anyone in the workforce. Hence, more often than not, a minimum wage ends up helping the privileged and ignoring the needy. To end poverty, a minimum wage should be determined for households and not individuals. This will facilitate the redistribution of income to poor families over low-earners of rich families. Simultaneously, governments must increase spending on education and skill development to build an economy with a speedily employable workforce, hence fostering growth and development. A minimum wage policy also needs to tackle the problem of incomplete and irregular legal coverage. Although minimum wages seem to be extensively applicable, in several cases the coverage is ineffective and disregards those most in need of social security, such as domestic workers or homeworkers. By neglecting a few crucial sectors of the economy, we fail to fully utilise the potential of minimum wage legislation. Even though legal coverage of the minimum wage developed from the mid-2000’s to the late 2000’s in India and South Africa, it covered only about 70% of low-paid workers by late 2000’s; in Peru, domestic workers were barred from the statutory minimum wage. Research suggests that weak legal coverage may at times ignore around one-third of all wage earners. We may confront this perplexity by undertaking comprehensive legislation that gratifies all sectors of an economy, and by ensuring that such legislation is strictly enforced. This, while a herculean task, can be accomplished by the extensive and intensive consultation of all stakeholders and a thorough analysis of a variety of socioeconomic and employment data. The minimum wage is fast becoming a universally adopted policy today and the principal question is how to operate the system in order to maximise its benefits. A conscientiously devised minimum wage policy can relegate low pay, inequalities, and poverty, at little or no adverse cost to employment. Yet, the minimum wage either continues to be low in many countries, or applies solely to certain select sectors. But with a little more fine-tuning, as I have suggested, I believe it is possible to shape an effective minimum wage policy that successfully reduces poverty and income inequalities across countries without hurting the job market.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">What Social Responsibility, if Any, Do or Should Corporations Have in Society Today?</title>
      <link href="/Corporate-Social-Responsibility" rel="alternate" type="text/html" title="What Social Responsibility, if Any, Do or Should Corporations Have in Society Today?" />
      <published>2019-02-14T21:30:00+00:00</published>
      <updated>2019-02-14T21:30:00+00:00</updated>
      <id>/Corporate-Social-Responsibility</id>
      <content type="html" xml:base="/Corporate-Social-Responsibility">&lt;p&gt;Consistent with McWilliams and Siegel’s approach in &lt;i&gt;The Academy of Management Review&lt;/i&gt;, we define Corporate Social Responsibility (CSR) as the spectrum of undertakings in which the firm goes beyond compliance and engages in “actions that appear to further some social good, beyond the interests of the firm”. It is said to be the company’s way of giving back to the community it is making so much out of, i.e. a sort of return gift.&lt;/p&gt;

&lt;p&gt;Gifts, of course, make consumers happy and this is the basic logic behind the social responsibility of corporations today: to make sure elated customers return to provide more business. This process of giving back to society adds to the goodwill of the company and ensures consumer loyalty. In professional language, this art of deceiving customers by producing a philanthropic image of a corporation is termed “corporate strategy”. It is a framework, as argued by Fombrun &amp;amp; Shanley in the &lt;i&gt;Academy of Management Journal&lt;/i&gt; that demonstrates how the reputation of a firm captures returns to socially responsible behaviour. Consumers tend to give more business to a firm that perhaps donates a part of its income to some village in Saharan Africa, than to one that does nothing of the sort or does something similar but of a lesser magnitude.&lt;/p&gt;

&lt;p&gt;For the same reason, Fortune 500 companies and multinational corporations are in a race over who can be more charitable, simply because CSR happens to have somewhat substituted direct advertising. Even though it is not legally required in most economies, companies seem to have diverted a significant proportion of their funds exclusively for CSR, rather than investing them in sales or advertising, as they traditionally did. They have realised that they can leverage social responsibility as a vehicle to bring customers to their doorstep, rather than making the effort of going to theirs. Therefore, we see a dramatic change in the policies of corporations today relative to just a few decades ago. They are using the same marketing budget in a much more efficient way and sustaining customer relationships by showing them a movie. The funny part is customers are actually enjoying the movie, but they fail to see the reality behind the seemingly altruistic endeavours of these corporations.&lt;/p&gt;

&lt;p&gt;In Disney’s classic retelling of the fable &lt;i&gt;Pinocchio&lt;/i&gt;, after the Blue Fairy grants him life, Geppetto’s wooden boy is granted a conscience. Now, since corporations do not have a conscience, they need a reliable external source to show them right from wrong. But what is that external source? Is it a set of laws like the several others these corporations never follow? Is it the government that in fact partners with them at times to privatise services like the provision of clean drinking water? Or is it people like you and me who are busy watching the movie these corporations are showing us?&lt;/p&gt;

&lt;p&gt;Corporations have always had just one responsibility – the responsibility to serve themselves. They do not care about the consequences their activities have on society. After being declared “legal persons”, 288 of the 307 appellants who sought jurisdiction of the Supreme Court of the United States of America under the 14th Amendment, were corporations and not African-Americans, for whom the amendment had actually been made. This just goes on to prove how self-centred and blatantly selfish corporations are. But wait a minute, why shouldn’t they be?&lt;/p&gt;

&lt;p&gt;Whether it be harm to human health by companies such as Monsanto or harm to the environment by a variety of industries, corporations can cross any limits and employees need not even regret their wrongdoings because well – limited liability – they’re safe! How can they be held accountable for decisions that a corporation took? After all, a corporation doesn’t have the ability to base decisions on morals or feelings, then how can we expect it to be socially responsible? But then, what is the social responsibility of businesses?&lt;/p&gt;

&lt;p&gt;Milton Friedman once stated in the &lt;i&gt;The New York Times Magazine&lt;/i&gt;: “The social responsibility of business is to increase its profits.” Friedman wanted to clearly bring out a distinction between the legal and ethical aspects involved in the debate on social responsibility, by affirming that businesses are simply groups of people and that only people have responsibilities, not inanimate entities! To quote J. Hood of the &lt;i&gt;Foundation for Economic Education&lt;/i&gt;“If a corporation makes a donation to charity without the shareholders’ authorization, wrote Friedman, the managers are deciding how to spend other people’s money. It would be better to return the money to shareholders as dividends or capital gains and let them decide which charities to support.”&lt;/p&gt;

&lt;p&gt;An alternative and opposite theory to Friedman’s was developed by Freeman, who argued in his book &lt;i&gt;Strategic Management: A Stakeholder Approach&lt;/i&gt; that corporate social responsibility is a vital part of strategic management. His argument was based on the thought that firms are associated with numerous parties whose interests should be considered, since the firm can’t continue to survive without the support of these stakeholders – employees, customers, suppliers and the community. This view was expanded by Donaldson &amp;amp; Davis by the introduction of Stewardship Theory in the&lt;i&gt;Australian Journal of Management&lt;/i&gt;. According to this theory, there is a moral imperative for managers to “do the right thing,” without regard to how such decisions affect the firm’s financial performance. This rationale becomes difficult to adhere to internationally, because there may be no consensus on what “the right thing” is. However, this was a more ethically-centred approach.&lt;/p&gt;

&lt;p&gt;But there’s a simpler question to be asked in all this scholarly debate. Before managing social responsibility outside their organisation, shouldn’t corporations focus on fulfilling their internal social responsibility? Paying a few cents to workers who produce products that sell for hundreds of dollars! Is it not hypocritical of companies to talk big about social responsibility while they exploit their own employees? It is clear to me that corporations survive on externalities and that they are purely utilitarian. They want to make others pay the cost for their impact on society, while they luxuriate in soaring profits. But then again, isn’t this why corporations exist in the first place?&lt;/p&gt;

&lt;p&gt;I believe corporations do have a social responsibility, however, that responsibility predominantly lies confined to their own internal affairs: first, the demands of employees, financers and executives ought to be delivered. Commercial activity in itself comes with social benefits such as greater employment, improved standards of living, globalisation and a better quality of life. These benefits aren’t derived from any extra effort by corporations – it’s not obligatory for them to put in extra effort anyway – but they are derived simply by virtue of the existence of corporations. Since a corporation can’t think and feel like a human with flesh and blood, it need not care about any other social responsibility, unless it comes with an advantage. If community giving helps boost sales and multiply profits, implement CSR. This means we’ll still be watching a movie, however, there will certainly be a simultaneous social impact, to whatever small extent possible. So, corporations may consider their dedicated business undertakings a social responsibility, or, their newfound marketing technique – either one suits me…as long as it does some good, especially to those people on whom the corporation truly depends for its profits.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Shivang Singh</name>
        
        
      </author>

      

      
        <category term="economics" />
      

      
        <summary type="html">Consistent with McWilliams and Siegel’s approach in The Academy of Management Review, we define Corporate Social Responsibility (CSR) as the spectrum of undertakings in which the firm goes beyond compliance and engages in “actions that appear to further some social good, beyond the interests of the firm”. It is said to be the company’s way of giving back to the community it is making so much out of, i.e. a sort of return gift.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">How does Finance Benefit Society?</title>
      <link href="/How-Finance-Benefits-Society" rel="alternate" type="text/html" title="How does Finance Benefit Society?" />
      <published>2019-02-07T04:28:00+00:00</published>
      <updated>2019-02-07T04:28:00+00:00</updated>
      <id>/How-Finance-Benefits-Society</id>
      <content type="html" xml:base="/How-Finance-Benefits-Society">&lt;p&gt;There are several theories that illustrate the crucial role played by finance in the world today: managing risk, providing important price signals, curbing agency problems and eliminating informational irregularities being the most essential ones. There is adequate evidence that demonstrates how finance fosters growth, promotes entrepreneurship, favours education, alleviates poverty and reduces inequality. Yet, this impression is not subscribed to by society at large. The global financial crisis, that erupted in September 2008, propelled economies around the world towards recession. It destabilized several major financial institutions in the US and elsewhere, while severely damaging the global economy. A sample of American adults was surveyed in 2015, three years after the end of the Great Recession and seven years since the financial crisis. They were asked: &lt;i&gt;“Overall, how much, if at all, do you think the US financial system benefits or hurts the US economy?”&lt;/i&gt; An aggregate of 48% responded that finance hurts the US economy; only 34% said that it benefits it, while the remaining could not comment.&lt;/p&gt;

&lt;p&gt;This sentiment is not just the result of the crisis: throughout history, finance has been perceived as a ‘rent-seeking’ activity. The aftermath of the 2007-08 financial crisis has only worsened this view. Prohibitions against finance date as far back as the Old Testament. From Libor fixing to exchange rate manipulation; from gold price rigging to outright financial fraud in subprime mortgages, not a day passes without news of a fresh financial scandal. But, why does this happen? Financial capitalism periodically undergoes a systemic crisis. Kotz (2008) validates that the crisis of 2008 exemplified a &lt;em&gt;“neoliberal form of capitalism”&lt;/em&gt;. This capitalism intensively promoted economic liberalization policies such as privatisation, deregulation and free trade. And this process disproportionately and perversely empowered financial institutions, hence helping the sector create a profiteering monopoly of its own.&lt;/p&gt;

&lt;p&gt;The result was intricately planned scandals that duped customers of their savings, retirement funds, pensions, and homes; while financial institutions continued to build their empire on the relics of their crimes. The seeds of the 2008 catastrophe were sown in the credit explosion that peaked in 2007, which was characterised by the reckless dispensing of subprime mortgages, a consequent growth of the housing bubble, and amplified predatory lending and overleveraging by investment banks. Financial institutions in the US had placed bets against Collateralized Debt Obligations (CDOs), they had deliberately sold to customers who couldn’t afford to pay back. The implication? Billions in profits for investors and insurance companies. Until, of  course, the financial sector witnessed panic and turmoil following the bankruptcy of Lehman Brothers and Merrill Lynch, and government seizures of Fannie Mae, Freddie Mac, and AIG. Prices across commodities dropped, employment fell drastically, the cost of corporate and bank borrowing rose substantially, and financial market volatility rose to levels that have rarely been seen. The &lt;em&gt;“neo-capitalistic era”&lt;/em&gt; ended up sponsoring misery and deprivation.&lt;/p&gt;

&lt;p&gt;But what aided this wreckage? Over the years, the financial sector has been able to apprehend the political system of countries across the globe. CEOs and other top executives of banks and other financial institutions end up holding important positions in government administration, thus endowing exclusive benefits to the financial sector. Ken Lay, the Chairman of Enron, was very close to the Bush family. He serves as a pertinent representation of the border where finance meets politics. George H. Bush had helped &lt;em&gt;“Kennie Boy”&lt;/em&gt; secure subsidies and other benefits for the company. Ken had also been proclaimed mascot of the new era of deregulation. To continue a favourable relationship with the government, Enron had made enormous financial contributions towards the Presidential campaign of Bush Jr.&lt;/p&gt;

&lt;p&gt;Another accurate example of the finance-politics companionship was the merger of Citicorp and Travelers to form Citigroup, which violated the Glass-Steagall Act. However, instead of criminally prosecuting Citigroup, Congress passed the Gramm-Leach-Bliley Act of 1999, legalizing the merger. Analogously, in May 1999, Brooksley Born of the Commodity Futures Trading Commission (CFTC) had proposed legislation to regulate the derivatives market. In response to this, the then Secretary of the Treasury, Larry Summers, instructed her to withdraw her proposal immediately. Furthermore, Alan Greenspan, Robert Rubin, and US Securities and Exchange Commission Chairman, Arthur Levitt, came up with a joint-statement condemning Born’s proposal. Finally, to ice the cake, The Commodity Futures Modernization Act of 2000 was passed by the Congress, which banned the regulation of derivatives. All this had been done to maintain the profit standards of the unregulated market. These examples point to the immoral and corrupt disposition of &lt;em&gt;“Wall Street governments”&lt;/em&gt;. There seems to be a blatant disregard for the impact their actions have on society. Not a single financial services firm had been prosecuted criminally for securities or accounting fraud till mid-2010. The agencies that blindly distributed ‘Triple-A’ ratings to disastrous loans had also not been castigated appropriately. Kristin Davis’ account of the 10,000 frequent customers in her prostitution racket, 40-50% of which were from Wall Street, enlightens us on how the financial sector is still indulging in complete hedonism.&lt;/p&gt;

&lt;p&gt;Today, we readily tend to associate finance with the mortgage and debt hangover that plagued the world back in 2008. However, notwithstanding anything said previously in this article, finance should not be condemned as a system of recklessness. Even though critics are right in some of their accusations, we cannot term finance a curse for the society. It might not be a boon either, but we can improve it through transformation and reform; these changes should focus on broadening the scope of financial innovation rather than confining it. We must work towards achieving a refined, more fundamental, expedient, and sustainable form of finance that serves the society before serving itself.&lt;/p&gt;

&lt;p&gt;Finance is meant to extend support to social goals – greater employment, economic welfare, wider education, skill development and equality, among several other things. It should be seen as a tool that can, in fact, ensure a more prosperous and unregimented society. I believe that, while financial capitalism and financial innovation collectively shape the way forward, regulations, restrictions, corporate governance, and risk management should be pragmatically enforced in order to help financial institutions function in the interests of society. It can be thought of as merely codifying rules of a game; rules that are best conceived by the players of the game themselves. As Shiller (2013) states, &lt;i&gt;“imperfect as our financial system is, I still find myself admiring it for what it does, and imagining how much more impressive it can be in the future.”&lt;/i&gt; Think about insurance: thriving in modern society would be impossible without it, or, for that matter, banking, mortgages or even pensions. It is an interesting yet unknown fact that the word ‘finance’ has actually been derived from a classical Latin word for ‘goal’. It reflects our interests in careers, hopes for our families, ambitions for our businesses, aspirations for our culture, and ideals for our society. Finance does not tell us what the goals are; finance itself does not embody a goal either. Finance is the goal…&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Shivang Singh</name>
        
        
      </author>

      

      
        <category term="economics" />
      

      
        <summary type="html">There are several theories that illustrate the crucial role played by finance in the world today: managing risk, providing important price signals, curbing agency problems and eliminating informational irregularities being the most essential ones. There is adequate evidence that demonstrates how finance fosters growth, promotes entrepreneurship, favours education, alleviates poverty and reduces inequality. Yet, this impression is not subscribed to by society at large. The global financial crisis, that erupted in September 2008, propelled economies around the world towards recession. It destabilized several major financial institutions in the US and elsewhere, while severely damaging the global economy. A sample of American adults was surveyed in 2015, three years after the end of the Great Recession and seven years since the financial crisis. They were asked: “Overall, how much, if at all, do you think the US financial system benefits or hurts the US economy?” An aggregate of 48% responded that finance hurts the US economy; only 34% said that it benefits it, while the remaining could not comment.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Tobacco and Marketing: An Anomaly?</title>
      <link href="/Tobacco-and-Marketing-An-Anomaly" rel="alternate" type="text/html" title="Tobacco and Marketing: An Anomaly?" />
      <published>2019-02-07T03:57:00+00:00</published>
      <updated>2019-02-07T03:57:00+00:00</updated>
      <id>/Tobacco-and-Marketing-An-Anomaly</id>
      <content type="html" xml:base="/Tobacco-and-Marketing-An-Anomaly">&lt;p&gt;In September 1995, Pierre Omidyar, a 28-year old computer programmer finished the code for what would soon become eBay. Searching around for a test item, he put up a broken laser pointer for sale with the base price as $1. The laser pointer sold for $14.83. Shocked, Omidyar contacted the winning bidder to make sure he understood the laser pointer was broken. “Oh yes”, the bidder replied, “I am a collector of broken laser pointers.” Trade creates value by moving goods from people who value them less to people who value them more. Tobacco happens to be a product valued greatly by a variety of stakeholders. It is for this reason that we continue to trade and rampantly consume it in spite of its tribulations.&lt;/p&gt;

&lt;p&gt;Much like the laser pointer, tobacco products are also ‘broken’ goods – unfit for use. Regardless, however, one can always find people wanting to purchase them, even if they have to bid high to acquire them. But, has anyone cared to wonder why? The answer to this question is obscure and complicated, yet evident and simple: &lt;i&gt;“They are cool, available, and addictive.”&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;How are they cool? Well, celebrities endorse them in movies; Mickey Mouse, Popeye and The Flintstones on television. Why are they available? Probably because we want them, just as governments want their tax revenues and companies their profits. But they are addictive! Are McDonald’s, PUBG, and One Direction not? Tobacco products are like any other commodity. They have a demand and hence a supply. Now, in order to help demand meet supply, companies need to reach out to consumers by marketing themselves. These companies too, are like all other companies. They have a profit maximisation target and hence a purpose for existence.&lt;/p&gt;

&lt;p&gt;However, despite having brought the tobacco industry at par with other industries, can we permit it to be part of the same marketing ambit? Or can we even permit it to market its products in the first place?&lt;/p&gt;

&lt;p&gt;The earliest known advertisement in the United States was for the snuff and tobacco products of &amp;lt;P. Lorillard and Company and was placed in the New York daily papers in 1789. Advertising was an emerging concept, and tobacco-related advertisements were not seen as any different from those for other products: their negative impact on health was unknown at the time. American Tobacco was engaged in competitive advertising of its Bull Durham chewable tobacco leaves as well. Around the Great Depression, it ran campaigns like the &lt;i&gt;“Roll Your Own”&lt;/i&gt; campaign and boosted outdoor advertising by way of elegant wall paintings and graffiti. These cleverly designed advertisements were made to persuade the lower and middle-class masses to imitate the upper-class gentry by purchasing elite yet economical tobacco products: a bag of tobacco for just a nickel at the time. Through their &lt;i&gt;“Hit the Bull”&lt;/i&gt; campaign, the Blackwell Company was able to rope in baseball players to endorse their brand. If we observe carefully, such marketing techniques are not only ludicrous but also morally unacceptable today. An advertisement depicting class distinction would bring doom upon the company, and no sports person would endorse these products, parents would rush to scrape off wall paintings before their children could have a glance. Why is there this sudden change in our attitude towards tobacco? It is generally a legal substance after all, unless specifically prohibited as done in a few countries…&lt;/p&gt;

&lt;p&gt;The answer lies in our awareness: I believe we are more informed about the dangers of tobacco than ever before. The first noteworthy scientific report concerning the dangers of cigarettes was published in 1964, by the Surgeon General of the United States. Terry (1964) illustrates important deductions by the Advisory Committee – smoking was found to be: “A cause of lung cancer and laryngeal cancer in men, a probable cause of lung cancer in women, the most important cause of chronic bronchitis.”&lt;/p&gt;

&lt;p&gt;Senators in the US, thereafter, passed several laws to regulate the advertising of tobacco products. The Federal Cigarette Labeling and Advertising Act of 1965 mandated all cigarette boxes to come with a warning label. In 1971, there was a ban on the advertisement of tobacco products on television and radio. Countries like Australia have defeated giants like Philip Morris by legislating “plain packaging” of cigarettes in order to intensify the fight against tobacco. Very similar to a depiction in the movie &lt;i&gt;Thank you for Smoking&lt;/i&gt;(2005), cigarette companies in India have attempted partnering with Bollywood to get celebrities to promote smoking. The government has hence made it mandatory to include cautionary messages in films and music videos that show people smoking. This comes in response to cigarette companies trying to attract and indulge youngsters in embracing their poison. &lt;i&gt;“They try to hook our kids using cartoons and symbols.”&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;The global population of smokers increased from 721 million in 1980 to 967 million in 2012, and the number of cigarettes smoked has risen from 4.96 trillion to 6.25 trillion between the same time periods. Of the 1.22 billion smokers today, 1 billion of them live in developing or transitional economies. Rates of smoking have levelled off or declined in the developed world. In the developing world, tobacco consumption is rising by 3.4% every year. In 2002, about 20% of teens aged 13 to 15 smoked tobacco worldwide. Approximately 80,000 to 100,000 children in this age bracket begin smoking every day. Half of those who begin smoking in adolescent years are projected to go on to smoke for 15 to 20 years. Today’s teenager is tomorrow’s potential regular customer. It has been rightly said that &lt;i&gt;“tobacco takes care of its own”&lt;/i&gt; and own only: an invisible Invisible Hand.&lt;/p&gt;

&lt;p&gt;Against all odds, we are striving to change the &lt;i&gt;“smoking is cool”&lt;/i&gt; notion, we are motivated to invent new kinds of alternatives that are not ‘addictive’ and also come up with treatments for lung diseases, but, in the face of our numerous measures to counter the tobacco menace, nothing really seems to be working. Probably because of its extensive ‘availability’ that no one is willing to put an end to. Why would they? The global spending, right from manufacturing cigarettes to treating the diseases they leave behind, is unbelievably enormous. The tobacco industry generates an income for not only its own farmers and employees but also other industries, their stakeholders, and governments at large. In 2014, tobacco companies spent more than $9 billion on marketing cigarettes and smokeless tobacco in the United States. This amount translates to nearly $25 million each day, or about $1 million every hour (Federal Trade Commission, 2016). Smoking-related illness in the United States costs more than $300 billion each year (US Department of Health and Human Services, 2014). Notwithstanding the economic wonders (including tax revenues) it is doing, only truly passionate, non-profit, non-governmental organizations are capable of opposing the ‘availability’ of tobacco. But, how many of these godly organizations actually exist?&lt;/p&gt;

&lt;p&gt;After having intricately analyzed the trade mechanics of tobacco and its marketing approach, I can obviously agree that tobacco products do not qualify as ethically marketable products. I will certainly not provide marketing services to Big Tobacco or be one of those lawyers that protect cigarette companies in lawsuits. However, this being said, I also do not believe it is morally correct for us to deprive tobacco companies of access to marketing. Should it be regulated? Absolutely. Can we allow it to cater to all age groups? Absolutely not. But should we not ban its marketing completely? If and only if we are also banning cigarettes and all other forms of tobacco. Half-convinced that would never happen, I believe there at least needs to be stringent legislation on a code of conduct for tobacco firms to follow for advertisement of their products locally. What is ethical for one country might be the gravest of crimes for another. We cannot have a universal code of conduct in this aspect, nor can we decide for legal consumers: that would be morally presumptuous. After all, they have a choice of their own.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Shivang Singh</name>
        
        
      </author>

      

      
        <category term="economics" />
      
        <category term="trending" />
      

      
        <summary type="html">In September 1995, Pierre Omidyar, a 28-year old computer programmer finished the code for what would soon become eBay. Searching around for a test item, he put up a broken laser pointer for sale with the base price as $1. The laser pointer sold for $14.83. Shocked, Omidyar contacted the winning bidder to make sure he understood the laser pointer was broken. “Oh yes”, the bidder replied, “I am a collector of broken laser pointers.” Trade creates value by moving goods from people who value them less to people who value them more. Tobacco happens to be a product valued greatly by a variety of stakeholders. It is for this reason that we continue to trade and rampantly consume it in spite of its tribulations.</summary>
      

      
      
    </entry>
  
</feed>
