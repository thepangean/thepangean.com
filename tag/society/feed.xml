<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator>
  <link href="/tag/society/feed.xml" rel="self" type="application/atom+xml" />
  <link href="/" rel="alternate" type="text/html" />
  <updated>2021-05-15T01:00:27+00:00</updated>
  <id>/tag/society/feed.xml</id>

  
  
  

  
    <title type="html">The Pangean | </title>
  

  
    <subtitle>Taking a step back</subtitle>
  

  

  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
  

  
    <entry>
      <title type="html">The Spirit of Brahminism and the Capitalist Reckoning</title>
      <link href="/The-Spirit-of-Brahminism-and-the-Capitalist-Reckoning" rel="alternate" type="text/html" title="The Spirit of Brahminism and the Capitalist Reckoning" />
      <published>2021-04-18T00:00:00+00:00</published>
      <updated>2021-04-18T00:00:00+00:00</updated>
      <id>/The-Spirit-of-Brahminism-and-the-Capitalist-Reckoning</id>
      <content type="html" xml:base="/The-Spirit-of-Brahminism-and-the-Capitalist-Reckoning">&lt;p&gt;The Indian caste system was (or is) a most dehumanising, totalitarian and rigid system of social hierarchy and control. The oldest Hindu religious text, the Rig Veda, in its canto 10, hymn 90 defines how mankind came to be from the different parts of the supreme primordial being. It declares that &lt;em&gt;&quot;The Brahmin was His [i.e. the primordial being's] mouth; the Kshatriya His arms became. His thighs were the Vaisya; of His feet the Sudra was born.&quot;&amp;nbsp;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;These four castes: the Brahmins (the priestly and intellectual class), the Kshatriyas (the landowners and warriors), the Vaisya (the business class) and the Sudra (the labourer) represent the idealised division of social groups in the feudal social order of ancient India. The castes do not intermarry, they do not undertake work outside the profession assigned to their caste and the lowest castes and the outcastes are considered 'untouchable'.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;One would think that capitalism, as the fundamental counterfoil to a feudal social order, has nothing to do with the caste system or anything like it. After all, capitalism is supposed to be a system in which the invisible hand of the market determines productive activity, rather than a system where a rigid hierarchy dictates social outcome. It is supposed to be based on open competition, where the best product wins, a rational social order, as Max Weber argued, instead of an irrational social order based on blood purity and ancient hymns on a primordial being.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;But funny enough, the adaptability of the capitalist mode of production to varied challenges means that capitalism is evolving itself into a social hierarchy that looks very much like the caste system. More specifically, it is evolving to give us a group of people who are verily like the Brahmins of the Hindu social order, the mouths of the primordial being that is Capital.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The group I speak of here is quite easily recognisable and thoroughly glamourised (and demonised) in world culture. Their activities are difficult to understand. They deal in items of pure abstraction, building nothing themselves but exercising control over all that is built. They are an exclusive club of people with an iron grip over power and money, whilst not being owners of any of those things themselves. They are the investment bankers, the equity analysts, the financiers and the asset managers.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Like the Brahmin of yore who technically lived on alms but amassed vast wealth, the asset manager and the investment banker only shift wealth around but is rich &quot;via commission motherf*cker&quot; (to quote Matthew McConaughey's character from &lt;em&gt;Wolf of Wall Street&lt;/em&gt;). Like the Brahmin who would zealously guard his secret knowledge of the sacred mantras and rituals which could make a mere warlord into a king, so does the Wall Street professional speak in the complex technical jargon of 'bonds', 'short-selling', 'derivatives' and 'collateralised debt obligations' which turn a mere productive activity into a sophisticated web of transactions. Like the killing of a Brahmin was the highest crime under ancient Hindu law, so is not bailing out the big banks and financial firms an impossibility.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;These parallels are not some mere curiosity, they showcase how capitalism is so eminently adaptable to changing social conditions and how it verily controls the change in material conditions through its social architecture. In fact, this parallel upsets the fundamental assumptions that both pro-capitalist and many anti-capitalist thinkers make. It is not just the chains of economic power which define social relations, it is also the makeup of social relations that determines where economic power resides. The lords of high finance do not derive their power by owning and controlling the means of production. Instead, they define the interrelationships between economic power and those subject to its dominion.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;We can really appreciate this with a comparative example of the exercise of Brahminical power and the exercise of the power of the financiers. In the ancient Hindu fire rituals called the&lt;em&gt; yagna&lt;/em&gt;, the Brahmin priest would declare the officiator of the ritual as the '&lt;em&gt;yajaman'&lt;/em&gt;, he would make oblations to the various gods in the name of the &lt;em&gt;yajaman&lt;/em&gt;. The fruits of the &lt;em&gt;yagna&lt;/em&gt; would technically be available to the &lt;em&gt;yajaman&lt;/em&gt; alone, for it is his financial resources that make the &lt;em&gt;yagna&lt;/em&gt; possible. The Brahmin is a mere functionary in the entire process. But it is the Brahmin who knows the liturgy, it is the Brahmin who understands the secrets of the various rituals which confer wealth and power. In other words, it is the Brahmin who creates the&lt;em&gt; yajaman&lt;/em&gt; and the &lt;em&gt;yagna.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In a similar way, the financier of today creates the capital and the capitalist. It is he who decides if a company can go public, it is he who sells its shares with an asking price and aims to raise capital with it. While the Brahmin made oblations to the gods, as a mere agent of the capitalist, the financier makes his oblations to the market. Technically, the financier is a mere agent. But it is he who knows the viability of the assets of the company, it is he who knows how to appease the market in favour of the capitalist.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;However, as already alluded to, there is a stark difference between the Brahmin and the financiers: while one functions in a mystical social order, the other works in a rationalist one. So the interesting question is: why does this similarity emerge at all? Why is capitalism starting to look like feudalism?&lt;/p&gt;
&lt;p&gt;The answer is at once simple and complicated. It resides in that confusing term - 'human nature’.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;It is known that we hunger, not just for food or shelter but also for meaning and security. We are, on some level, aware of our mortality and of how the universe is an uncaring void. At a time when there was no guarantee that the next harvest would give yield when natural disaster and disease could so easily destroy so many lives, the &lt;em&gt;yagna &lt;/em&gt;or the fire rituals gave humanity a sense of security. They made humanity feel a sense of control over its destiny in a fundamentally uncertain time. That is why the Brahmin was given a place of pride and of supreme importance in such an order, for on him rested society's basic sense of peace and order.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;In the present time, while our fears are not related to the next harvest, our fundamental existential dread remains the same. We do not know what exactly the market will demand next year, we do not know whether the invisible hand will drive prices up or down, whether wages will increase or decrease. Even if our order is rational, our fears of hunger and pain are not, we cannot live with the uncertainty of knowing that a mechanism of market forces will determine our bank balance, especially when the world is buffeted by the COVID-19 pandemic. The financier, by exercising influence and control over the market, gives us certainty. That is why he (or she) has so much power.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;To go even deeper, the emergence of late capitalism represents the ultimate reckoning of the Age of Reason with its own assumptions. And the financier in late capitalism, advisedly or inadvertently, represents the reckoner. He confronts humanity with the limitations of his own rationalist systems. Nowhere is this more obvious than in the 2008 crisis. That crisis was, in many ways, completely and utterly the consequence of human beings trying to be too smart for their own good. Bankers so cleverly thought that if debts on homes were combined and converted into their own kind of mega debt, with that mega debt being sold in a market as a good, then money would just flow forever.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The mega debts or ‘mortgage-backed securities’ as they were called, were a pure abstraction. They had no existence outside a system of pure formal logic, where obligations to pay back a home loan, which has no palpable existence, could be treated as a commodity and combined and sold as another obligation to pay back a loan, which also had no palpable existence. The real thing, the palpable thing: the home and the homeowner who undertook to pay back the loan was an eminently forgettable assumption in the hyper-rational mind of the financier. Needless to say, the results of this near-mystical, Brahminical rationalism are for all to see and they represent how there is such great folly in assuming that man is a creature of reason.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;So, the ultimate question is: where do we go now? Will this inherent contradiction within capitalism unravel the same? (As Marx suggested) I think not. If the strength of the Brahmanical social order is any guide, a social order, no matter how flawed, no matter how decidedly routed by reality can maintain its spell, for that very weakness called human nature which in its yearning for security would rather believe the immediate lie than imagine a greater truth. So, the only thing that late capitalism and its Brahmin, the financier, tells us that it is here to stay no matter how many crises come and go. Unless, of course, humanity plucks up the courage to say: &quot;creatures of the heart and the flesh unite, we have nothing to lose but our rational brains''.&amp;nbsp;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Harsh Tiwari</name>
        
        
      </author>

      

      
        <category term="trending" />
      
        <category term="society" />
      

      
        <summary type="html">The Indian caste system was (or is) a most dehumanising, totalitarian and rigid system of social hierarchy and control. The oldest Hindu religious text, the Rig Veda, in its canto 10, hymn 90 defines how mankind came to be from the different parts of the supreme primordial being. It declares that &quot;The Brahmin was His [i.e. the primordial being's] mouth; the Kshatriya His arms became. His thighs were the Vaisya; of His feet the Sudra was born.&quot;&amp;nbsp; These four castes: the Brahmins (the priestly and intellectual class), the Kshatriyas (the landowners and warriors), the Vaisya (the business class) and the Sudra (the labourer) represent the idealised division of social groups in the feudal social order of ancient India. The castes do not intermarry, they do not undertake work outside the profession assigned to their caste and the lowest castes and the outcastes are considered 'untouchable'.&amp;nbsp; One would think that capitalism, as the fundamental counterfoil to a feudal social order, has nothing to do with the caste system or anything like it. After all, capitalism is supposed to be a system in which the invisible hand of the market determines productive activity, rather than a system where a rigid hierarchy dictates social outcome. It is supposed to be based on open competition, where the best product wins, a rational social order, as Max Weber argued, instead of an irrational social order based on blood purity and ancient hymns on a primordial being.&amp;nbsp; But funny enough, the adaptability of the capitalist mode of production to varied challenges means that capitalism is evolving itself into a social hierarchy that looks very much like the caste system. More specifically, it is evolving to give us a group of people who are verily like the Brahmins of the Hindu social order, the mouths of the primordial being that is Capital.&amp;nbsp; The group I speak of here is quite easily recognisable and thoroughly glamourised (and demonised) in world culture. Their activities are difficult to understand. They deal in items of pure abstraction, building nothing themselves but exercising control over all that is built. They are an exclusive club of people with an iron grip over power and money, whilst not being owners of any of those things themselves. They are the investment bankers, the equity analysts, the financiers and the asset managers.&amp;nbsp; Like the Brahmin of yore who technically lived on alms but amassed vast wealth, the asset manager and the investment banker only shift wealth around but is rich &quot;via commission motherf*cker&quot; (to quote Matthew McConaughey's character from Wolf of Wall Street). Like the Brahmin who would zealously guard his secret knowledge of the sacred mantras and rituals which could make a mere warlord into a king, so does the Wall Street professional speak in the complex technical jargon of 'bonds', 'short-selling', 'derivatives' and 'collateralised debt obligations' which turn a mere productive activity into a sophisticated web of transactions. Like the killing of a Brahmin was the highest crime under ancient Hindu law, so is not bailing out the big banks and financial firms an impossibility.&amp;nbsp; These parallels are not some mere curiosity, they showcase how capitalism is so eminently adaptable to changing social conditions and how it verily controls the change in material conditions through its social architecture. In fact, this parallel upsets the fundamental assumptions that both pro-capitalist and many anti-capitalist thinkers make. It is not just the chains of economic power which define social relations, it is also the makeup of social relations that determines where economic power resides. The lords of high finance do not derive their power by owning and controlling the means of production. Instead, they define the interrelationships between economic power and those subject to its dominion.&amp;nbsp; We can really appreciate this with a comparative example of the exercise of Brahminical power and the exercise of the power of the financiers. In the ancient Hindu fire rituals called the yagna, the Brahmin priest would declare the officiator of the ritual as the 'yajaman', he would make oblations to the various gods in the name of the yajaman. The fruits of the yagna would technically be available to the yajaman alone, for it is his financial resources that make the yagna possible. The Brahmin is a mere functionary in the entire process. But it is the Brahmin who knows the liturgy, it is the Brahmin who understands the secrets of the various rituals which confer wealth and power. In other words, it is the Brahmin who creates the yajaman and the yagna.&amp;nbsp; In a similar way, the financier of today creates the capital and the capitalist. It is he who decides if a company can go public, it is he who sells its shares with an asking price and aims to raise capital with it. While the Brahmin made oblations to the gods, as a mere agent of the capitalist, the financier makes his oblations to the market. Technically, the financier is a mere agent. But it is he who knows the viability of the assets of the company, it is he who knows how to appease the market in favour of the capitalist.&amp;nbsp; However, as already alluded to, there is a stark difference between the Brahmin and the financiers: while one functions in a mystical social order, the other works in a rationalist one. So the interesting question is: why does this similarity emerge at all? Why is capitalism starting to look like feudalism? The answer is at once simple and complicated. It resides in that confusing term - 'human nature’.&amp;nbsp; It is known that we hunger, not just for food or shelter but also for meaning and security. We are, on some level, aware of our mortality and of how the universe is an uncaring void. At a time when there was no guarantee that the next harvest would give yield when natural disaster and disease could so easily destroy so many lives, the yagna or the fire rituals gave humanity a sense of security. They made humanity feel a sense of control over its destiny in a fundamentally uncertain time. That is why the Brahmin was given a place of pride and of supreme importance in such an order, for on him rested society's basic sense of peace and order.&amp;nbsp; In the present time, while our fears are not related to the next harvest, our fundamental existential dread remains the same. We do not know what exactly the market will demand next year, we do not know whether the invisible hand will drive prices up or down, whether wages will increase or decrease. Even if our order is rational, our fears of hunger and pain are not, we cannot live with the uncertainty of knowing that a mechanism of market forces will determine our bank balance, especially when the world is buffeted by the COVID-19 pandemic. The financier, by exercising influence and control over the market, gives us certainty. That is why he (or she) has so much power.&amp;nbsp;&amp;nbsp; To go even deeper, the emergence of late capitalism represents the ultimate reckoning of the Age of Reason with its own assumptions. And the financier in late capitalism, advisedly or inadvertently, represents the reckoner. He confronts humanity with the limitations of his own rationalist systems. Nowhere is this more obvious than in the 2008 crisis. That crisis was, in many ways, completely and utterly the consequence of human beings trying to be too smart for their own good. Bankers so cleverly thought that if debts on homes were combined and converted into their own kind of mega debt, with that mega debt being sold in a market as a good, then money would just flow forever.&amp;nbsp; The mega debts or ‘mortgage-backed securities’ as they were called, were a pure abstraction. They had no existence outside a system of pure formal logic, where obligations to pay back a home loan, which has no palpable existence, could be treated as a commodity and combined and sold as another obligation to pay back a loan, which also had no palpable existence. The real thing, the palpable thing: the home and the homeowner who undertook to pay back the loan was an eminently forgettable assumption in the hyper-rational mind of the financier. Needless to say, the results of this near-mystical, Brahminical rationalism are for all to see and they represent how there is such great folly in assuming that man is a creature of reason.&amp;nbsp; So, the ultimate question is: where do we go now? Will this inherent contradiction within capitalism unravel the same? (As Marx suggested) I think not. If the strength of the Brahmanical social order is any guide, a social order, no matter how flawed, no matter how decidedly routed by reality can maintain its spell, for that very weakness called human nature which in its yearning for security would rather believe the immediate lie than imagine a greater truth. So, the only thing that late capitalism and its Brahmin, the financier, tells us that it is here to stay no matter how many crises come and go. Unless, of course, humanity plucks up the courage to say: &quot;creatures of the heart and the flesh unite, we have nothing to lose but our rational brains''.&amp;nbsp;</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Rise of the New Age Nazis</title>
      <link href="/Rise-of-the-New-Age-Nazis" rel="alternate" type="text/html" title="Rise of the New Age Nazis" />
      <published>2021-04-18T00:00:00+00:00</published>
      <updated>2021-04-18T00:00:00+00:00</updated>
      <id>/Rise-of-the-New-Age-Nazis</id>
      <content type="html" xml:base="/Rise-of-the-New-Age-Nazis">&lt;p&gt;On December 14, 2020, the UK Labour party leader Keir Starmer appeared on the radio show LBC with host Nick Ferrari when a caller, introducing herself as ‘Gemma from Cambridge,’ took the opportunity to propagate the Neo-Nazi ‘Great Replacement’ conspiracy theory on a national media platform. She stated: “in the wake of organisations such as BLM and other racial advocacy groups pushing what’s best for their people, I just want to ask, should white people also start playing identity politics now, before they become a minority themselves by 2066?”&lt;/p&gt;
&lt;p&gt;This bizarre event was made even more bewildering when a Twitter user &lt;a href=&quot;https://twitter.com/redflareinfo/status/1338453892661714945&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;revealed&lt;/a&gt; that ‘Gemma from Cambridge’ was in fact Jody Swingler, a yoga teacher and musician living in Ibiza, a far cry from the archetypal image of the hapless neo-nazi social outcast in their parents’ basement, pulling the wings off flies and ranting on obscure online messageboards about how The Jews had prevented them from securing a girlfriend. Swingler had also &lt;a href=&quot;https://twitter.com/redflareinfo/status/1338453897258668033&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;recorded&lt;/a&gt; two YouTube shows with Mark Collett and Laura Melia, leaders of the white nationalist political party Patriotic Alternative, which &lt;a href=&quot;https://www.hopenothate.org.uk/wp-content/uploads/2020/08/HnH_Patriotic-Alternative-report_2020-08-v3.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;opposes&lt;/a&gt; the “replacement and displacement” of white Britons by people who “have no right to these lands.”&lt;/p&gt;
&lt;p&gt;It may seem striking that people who advocate new age, spiritual beliefs, previously associated with ‘flower power’ and the countercultural movement of the 1960's, could wind up on the same side as the far right. But in fact, the link between new age spirituality and extremist politics is not new. The Nazis drew support from the occultist Thule Society, and prominent Nazi figures such as Heinrich Himmler and Rudolf Hess endorsed homeopathy and alternative medicine, with Himmler supporting using plant extracts to cure cancer. In 1934, Hess set up an alternative medicine centre in Dresden. Their embrace of holism and spirituality, broadly, was underpinned by a rejection of the precepts of the Enlightenment, which posited that the world could be understood through logical processes, subordinating religious and monarchical obscurantism to the supremacy of the faculty of reason. Many Nazi figures saw a romanticised, agrarian age as a solution to the modern menaces of industrialisation and materialism. For example, Ernst Lehmann, a Nazi professor of botany, stated:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“We recognize that separating humanity from nature, from the whole of life, leads to humankind’s own destruction and to the death of nations. Only through a reintegration of humanity into the whole of nature can our people be made stronger… This striving toward connectedness with the totality of life, with nature itself, a nature into which we are born, this is the deepest meaning and the true essence of National Socialist thought.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A desire to undo the crude, materialist logic that undergirded liberal democracy, and to restructure the relationship between the citizen and the State, therefore, spawned the Nazis’ fascination with holism and the reintegration of man with nature. 'Blood and soil' meant an organic connection with one’s homeland that could not be expressed through the civic or legal frameworks engendered by the minority protection clauses of the League of Nations, but only through the maintenance of racial purity. Mark Mazower wrote in his book &lt;em&gt;Dark Continent &lt;/em&gt;that:“The League (of Nations) , after all, was an organisation of States. But what was the State? According to Hitler’s biological view of politics, it was no less than a ‘living organism,’” adding: “Hitler’s own vision of geopolitics unlike that of many geopoliticians — rested upon race: the State itself was merely an expression of the racial ‘Volk.’” Railing against the ‘juridification of politics,’ many Nazi legal theorists saw the nation as a biological organism, corruptible by outside influences and requiring protection from alleged Jewish subversion.&lt;/p&gt;
&lt;p&gt;What Marquette University history professor Peter Staudenmeier &lt;a href=&quot;https://newrepublic.com/article/154971/rise-ecofascism-history-white-nationalism-environmental-preservation-immigration&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;describes&lt;/a&gt; as the “link between a yearning for purity in the environmental sphere and a desire for racialized purity in the social sphere” also undergirds the ecofascist tendencies common to many modern neo-nazis such as Anders Brevik and the El Paso shooter, who characterised non-white populations as invaders seeking to despoil the environment through having more children and consuming more resources. This was also reflected in the writings of ecologist Garrett Hardin, &lt;a href=&quot;https://www.splcenter.org/fighting-hate/extremist-files/individual/garrett-hardin&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;listed&lt;/a&gt; by the SPLC (Southern Poverty Law Centre) as a white nationalist, who wrote about the supposed threats that overpopulation posed to the Earth’s future. The myth of overpopulation has, however, been roundly debunked; a &lt;a href=&quot;https://www.theguardian.com/environment/2020/sep/21/worlds-richest-1-cause-double-co2-emissions-of-poorest-50-says-oxfam#:~:text=1%20month%20old-,World's%20richest%201%25%20cause%20double%20CO2,of%20poorest%2050%25%2C%20says%20Oxfam&amp;amp;text=The%20wealthiest%201%25%20of%20the,2015%2C%20according%20to%20new%20research.&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;study&lt;/a&gt; from Oxfam showed that the world’s richest 1% are responsible for double the CO2 emissions of the poorest 50%.&lt;/p&gt;
&lt;p&gt;More recently, the contention that COVID-19 is a hoax has been a point of convergence between new age hippies and the far-right. Back in October, thousands of anti-vaxxers marched through Trafalgar Square in London at the COVID-sceptic ‘Unite for Freedom’ event, &lt;a href=&quot;https://twitter.com/nicktolhurst/status/1299729414767497219?lang=en&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;during which&lt;/a&gt; a BUF (British Union of Fascists) flag was spotted. The event was hosted by notorious conspiracy theorist David Icke, whose theories have been endorsed by both neo-nazis groups such as Combat 18, and the new age spiritual movement. It was also &lt;a href=&quot;https://www.independent.co.uk/news/world/americas/us-election-2020/jake-angeli-qanon-shaman-stormed-capitol-b1784091.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;revealed&lt;/a&gt; that Jake Angeli, a Trump supporter nicknamed the ‘QAnon shaman’ who stormed the Capitol, had stated that COVID-19 was a hoax. According to his mother, he had also refused to eat non-organic food.&lt;/p&gt;
&lt;p&gt;The two groups are united in their rejection of the perceived infringement on their liberties; in the case of the far-right, the supposed stifling of their ability to criticise the unaccountable technocracy that is allegedly imposing open borders and multiculturalism, and in the case of the new age conspiracists, the personal, bodily autonomy connoted by 'natural' methods of healing, which are at odds with modern, scientific forms of inoculation such as vaccines. The excoriation of Bill Gates as a central figure in a supposed global plot to undermine civil liberties by using vaccines as a method of social control, including implanting microchips into unfortunate victims, has also been &lt;a href=&quot;https://www.dailymotion.com/video/x64vj4&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;propagated&lt;/a&gt; by conspiracy theorist Alex Jones, who has suggested that vaccines are part of a government-induced eugenics programme.&lt;/p&gt;
&lt;p&gt;A theory known as the ‘Great Reset’ has also taken root in many far right circles, pushed by websites such as &lt;em&gt;Breitbart&lt;/em&gt;, which asserts that COVID-19 represents an attempt by a cabal of wealthy politicians, financiers and bureaucrats to establish a global government, eroding national sovereignty and dictating fiscal and monetary policy. During a &lt;a href=&quot;https://www.youtube.com/watch?v=ugRnjpXEwTo&amp;amp;t=114s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;conversation&lt;/a&gt; with former Alex Jones acolyte Paul Joseph Watson, &lt;em&gt;Breitbart&lt;/em&gt; columnist James Delingpole described the Great Reset as “another variation on the theme of the New World Order,” stating: “it’s a technocratic elite — an unelected technocratic elite — deciding how you and I should live our lives.”&lt;/p&gt;
&lt;p&gt;Scepticism towards authority and heightened awareness of the erosion of civil liberties by governments using crises as a pretext to usher in technocratic dominance is not without merit. In an era characterised by the technocratic monopolisation of communications by companies whose business models are predicated on mining consumer data, in which a global pandemic has drastically increased the purview of the State’s influence over the lives of ordinary citizens, and in which finance, industry and production have all been centralised in the hands of a few multinational corporations, it is not unreasonable to be wary of authoritarian overreach.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;However, the vague criticisms of systems of power enunciated by new age hippies, and the wild, conspiratorial denunciations of the ‘New World Order’ or the ‘Great Reset,’ common to extreme right wing political figures lack an empirical, material analysis. While it is certainly true that in Britain, at least, the pandemic has seen a worrying development in outsourcing the ‘Test and Trace’ system to companies such as G4S and Serco, which have been involved in nefarious operations from &lt;a href=&quot;https://www.bbc.co.uk/news/uk-england-sussex-51573510&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;setting up&lt;/a&gt; immigration detention centres to &lt;a href=&quot;https://www.justice.gov.uk/about/hmps/contracted-out&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;developing&lt;/a&gt; some of Britain’s first for-profit prisons, the potential for government overreach is no grounds for denying the existence, or the severity, of COVID-19.&lt;/p&gt;
&lt;p&gt;As outlined above, both aforementioned groups reject a materialist, empirically rigorous analysis of the global economy and the role of the State in abrogating civil liberties, idealising a preindustrial, agrarian past and asserting that the world’s problems are caused by a shadowy cabal (the root of most antisemitic conspiracy theories). This pandemic has shown that these groups, though widely considered to have diametrically opposed political interests, are more similar than they appear, and have been willing to set aside their ideological differences for the pursuit of wider goals. Unless their scepticism of the technocratic impulses of governments seeking to curtail civil liberties, much of which is justified, can be countered with a thorough and precise refutation of conspiratorial political narratives, the implications of this unholy alliance could be significant.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Tom Perrett</name>
        
        
      </author>

      

      
        <category term="society" />
      

      
        <summary type="html">On December 14, 2020, the UK Labour party leader Keir Starmer appeared on the radio show LBC with host Nick Ferrari when a caller, introducing herself as ‘Gemma from Cambridge,’ took the opportunity to propagate the Neo-Nazi ‘Great Replacement’ conspiracy theory on a national media platform. She stated: “in the wake of organisations such as BLM and other racial advocacy groups pushing what’s best for their people, I just want to ask, should white people also start playing identity politics now, before they become a minority themselves by 2066?” This bizarre event was made even more bewildering when a Twitter user revealed that ‘Gemma from Cambridge’ was in fact Jody Swingler, a yoga teacher and musician living in Ibiza, a far cry from the archetypal image of the hapless neo-nazi social outcast in their parents’ basement, pulling the wings off flies and ranting on obscure online messageboards about how The Jews had prevented them from securing a girlfriend. Swingler had also recorded two YouTube shows with Mark Collett and Laura Melia, leaders of the white nationalist political party Patriotic Alternative, which opposes the “replacement and displacement” of white Britons by people who “have no right to these lands.” It may seem striking that people who advocate new age, spiritual beliefs, previously associated with ‘flower power’ and the countercultural movement of the 1960's, could wind up on the same side as the far right. But in fact, the link between new age spirituality and extremist politics is not new. The Nazis drew support from the occultist Thule Society, and prominent Nazi figures such as Heinrich Himmler and Rudolf Hess endorsed homeopathy and alternative medicine, with Himmler supporting using plant extracts to cure cancer. In 1934, Hess set up an alternative medicine centre in Dresden. Their embrace of holism and spirituality, broadly, was underpinned by a rejection of the precepts of the Enlightenment, which posited that the world could be understood through logical processes, subordinating religious and monarchical obscurantism to the supremacy of the faculty of reason. Many Nazi figures saw a romanticised, agrarian age as a solution to the modern menaces of industrialisation and materialism. For example, Ernst Lehmann, a Nazi professor of botany, stated: “We recognize that separating humanity from nature, from the whole of life, leads to humankind’s own destruction and to the death of nations. Only through a reintegration of humanity into the whole of nature can our people be made stronger… This striving toward connectedness with the totality of life, with nature itself, a nature into which we are born, this is the deepest meaning and the true essence of National Socialist thought.” A desire to undo the crude, materialist logic that undergirded liberal democracy, and to restructure the relationship between the citizen and the State, therefore, spawned the Nazis’ fascination with holism and the reintegration of man with nature. 'Blood and soil' meant an organic connection with one’s homeland that could not be expressed through the civic or legal frameworks engendered by the minority protection clauses of the League of Nations, but only through the maintenance of racial purity. Mark Mazower wrote in his book Dark Continent that:“The League (of Nations) , after all, was an organisation of States. But what was the State? According to Hitler’s biological view of politics, it was no less than a ‘living organism,’” adding: “Hitler’s own vision of geopolitics unlike that of many geopoliticians — rested upon race: the State itself was merely an expression of the racial ‘Volk.’” Railing against the ‘juridification of politics,’ many Nazi legal theorists saw the nation as a biological organism, corruptible by outside influences and requiring protection from alleged Jewish subversion. What Marquette University history professor Peter Staudenmeier describes as the “link between a yearning for purity in the environmental sphere and a desire for racialized purity in the social sphere” also undergirds the ecofascist tendencies common to many modern neo-nazis such as Anders Brevik and the El Paso shooter, who characterised non-white populations as invaders seeking to despoil the environment through having more children and consuming more resources. This was also reflected in the writings of ecologist Garrett Hardin, listed by the SPLC (Southern Poverty Law Centre) as a white nationalist, who wrote about the supposed threats that overpopulation posed to the Earth’s future. The myth of overpopulation has, however, been roundly debunked; a study from Oxfam showed that the world’s richest 1% are responsible for double the CO2 emissions of the poorest 50%. More recently, the contention that COVID-19 is a hoax has been a point of convergence between new age hippies and the far-right. Back in October, thousands of anti-vaxxers marched through Trafalgar Square in London at the COVID-sceptic ‘Unite for Freedom’ event, during which a BUF (British Union of Fascists) flag was spotted. The event was hosted by notorious conspiracy theorist David Icke, whose theories have been endorsed by both neo-nazis groups such as Combat 18, and the new age spiritual movement. It was also revealed that Jake Angeli, a Trump supporter nicknamed the ‘QAnon shaman’ who stormed the Capitol, had stated that COVID-19 was a hoax. According to his mother, he had also refused to eat non-organic food. The two groups are united in their rejection of the perceived infringement on their liberties; in the case of the far-right, the supposed stifling of their ability to criticise the unaccountable technocracy that is allegedly imposing open borders and multiculturalism, and in the case of the new age conspiracists, the personal, bodily autonomy connoted by 'natural' methods of healing, which are at odds with modern, scientific forms of inoculation such as vaccines. The excoriation of Bill Gates as a central figure in a supposed global plot to undermine civil liberties by using vaccines as a method of social control, including implanting microchips into unfortunate victims, has also been propagated by conspiracy theorist Alex Jones, who has suggested that vaccines are part of a government-induced eugenics programme. A theory known as the ‘Great Reset’ has also taken root in many far right circles, pushed by websites such as Breitbart, which asserts that COVID-19 represents an attempt by a cabal of wealthy politicians, financiers and bureaucrats to establish a global government, eroding national sovereignty and dictating fiscal and monetary policy. During a conversation with former Alex Jones acolyte Paul Joseph Watson, Breitbart columnist James Delingpole described the Great Reset as “another variation on the theme of the New World Order,” stating: “it’s a technocratic elite — an unelected technocratic elite — deciding how you and I should live our lives.” Scepticism towards authority and heightened awareness of the erosion of civil liberties by governments using crises as a pretext to usher in technocratic dominance is not without merit. In an era characterised by the technocratic monopolisation of communications by companies whose business models are predicated on mining consumer data, in which a global pandemic has drastically increased the purview of the State’s influence over the lives of ordinary citizens, and in which finance, industry and production have all been centralised in the hands of a few multinational corporations, it is not unreasonable to be wary of authoritarian overreach.&amp;nbsp; However, the vague criticisms of systems of power enunciated by new age hippies, and the wild, conspiratorial denunciations of the ‘New World Order’ or the ‘Great Reset,’ common to extreme right wing political figures lack an empirical, material analysis. While it is certainly true that in Britain, at least, the pandemic has seen a worrying development in outsourcing the ‘Test and Trace’ system to companies such as G4S and Serco, which have been involved in nefarious operations from setting up immigration detention centres to developing some of Britain’s first for-profit prisons, the potential for government overreach is no grounds for denying the existence, or the severity, of COVID-19. As outlined above, both aforementioned groups reject a materialist, empirically rigorous analysis of the global economy and the role of the State in abrogating civil liberties, idealising a preindustrial, agrarian past and asserting that the world’s problems are caused by a shadowy cabal (the root of most antisemitic conspiracy theories). This pandemic has shown that these groups, though widely considered to have diametrically opposed political interests, are more similar than they appear, and have been willing to set aside their ideological differences for the pursuit of wider goals. Unless their scepticism of the technocratic impulses of governments seeking to curtail civil liberties, much of which is justified, can be countered with a thorough and precise refutation of conspiratorial political narratives, the implications of this unholy alliance could be significant.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Why Poorer Countries are More Conservative - As Told by the Brain</title>
      <link href="/Why-Poorer-Countries-are-More-Conservative-As-Told-by-the-Brain" rel="alternate" type="text/html" title="Why Poorer Countries are More Conservative - As Told by the Brain" />
      <published>2021-03-31T00:00:00+00:00</published>
      <updated>2021-03-31T00:00:00+00:00</updated>
      <id>/Why-Poorer-Countries-are-More-Conservative-As-Told-by-the-Brain</id>
      <content type="html" xml:base="/Why-Poorer-Countries-are-More-Conservative-As-Told-by-the-Brain">&lt;p&gt;There is no denying that people from different cultures have different attitudes towards life and the world around them. Some of these differences seem to lie between people living in the developed world and those living in the less developed nations, where people appear more liberal in the former and more conservative in the latter. An example of this phenomenon is attitudes towards homosexuality, while 32 out of the 54 African nations criminalise homosexuality, no country in Europe has a law expressly prohibiting homosexual activities. Contrasts in people’s attitudes between the developed and developing world can also be seen in other areas such as religion, premarital sex and even the modesty of female clothing. Additionally, just a century ago most, if not all, of today’s developed nations experienced a high rate of poverty. Back then, people’s mindsets were also what we would today call conservative, a prominent example of which was the prudency of people living in Victorian England.&lt;/p&gt;
&lt;p&gt;This raises one question: what is the link between the intangible mindsets of people living within a given society and the tangible advancement, or lack thereof, in said society? In order to assess the way humans behave, the most logical place to turn to is the brain. Brain scans have shown that people who self-identify as conservatives have a larger right amygdala; this is the area of the brain responsible for processing fear. This makes sense, given that in poor nations people tend to live in more fear than in their developed counterparts. Even within a developed nation such as the United States, it has been shown that shortly after the events of September 11, there was an increase in conservative leanings with increased support for military spending. If this is the state of a wealthy nation, what would it mean for one where people live fearfully on a day-to-day basis?&lt;/p&gt;
&lt;p&gt;There are a variety of ways in which the right amygdala, and by extension fear, would affect the way people behave in different countries. For instance, it goes without saying that citizens of conservative countries are traditional and resistant to change. A 2008 study, which catalogued the items in the dormitory rooms of university students, found that liberal-leaning students tended to own more books and travel-related items, which implied their desire for a sense of adventure in their lives. On the other hand, in conservative rooms, there were found to be more items including calendars and cleaning supplies, which were intended to maintain order in their lives. These findings suggest that liberals are more open to more novel experiences, whereas conservatives prefer more order and structure. This could explain the conservative inclination towards familiarity and hence resistance to change. Furthermore, their predisposition towards fear is potentially what makes them more risk-averse and resistant to what is not already an established norm.&lt;/p&gt;
&lt;p&gt;Many developing countries are also known for their populations’ intolerance across lines of ethnicity, religion or otherwise. A study conducted in 2018 showed that people with more conservative viewpoints were quicker to look away when shown disgusting images - such as vomit, faeces or blood - compared to those with more liberal leanings. From an evolutionary standpoint, this knee-jerk reaction is good for human survival, as this helps to avert potentially harmful pathogens. This quick reaction could also be encouraged by their aforementioned predisposition to fear. However, separate research also suggests that this affects the way in which conservatives view others who are different from themselves, which may explain the affinity towards intolerance in many developing nations. To add to that, this may also explain the negative attitude in such countries towards mental health and people with disabilities, which people perceive as ‘deviating’ from the norm.&lt;/p&gt;
&lt;p&gt;As far as religion goes, this itself is a factor that seems to differ between economic levels of development. In fact, there is a clear negative correlation between the GDP per capita of a country and the religiosity of its citizens according to a 2009 Gallup survey. This may also be linked to the predisposition towards fear, as religion is seen by many as a means of maintaining feelings of safety and security in the dangerous world around them.&lt;/p&gt;
&lt;p&gt;From these findings, it can be inferred that the conservative mentality is centred around fear and viewing the world as a dangerous place. There appears to be a tendency for inhabitants of liberal nations to judge those of conservative nations for being overly repressive and restrictive, while the latter judge the former as being immoral and depraved. One could argue, however, that neither side is right or wrong, only people’s brains adapt to the context around them, particularly in the context of fear where the brain tailors itself to aid in its owner’s survival. That having been said, the developed countries of today have only relatively recently seen widespread prosperity amongst their citizens and along with it only recently adopted their liberal ideas in the mainstream. Thus, we may have to wait for many other countries to develop to gauge whether such a correlation truly exists between a society’s physical development and the mentality of its citizens. There may well be one but for now, only time will tell.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Joseph Situmorang</name>
        
        
      </author>

      

      
        <category term="trending" />
      
        <category term="society" />
      

      
        <summary type="html">There is no denying that people from different cultures have different attitudes towards life and the world around them. Some of these differences seem to lie between people living in the developed world and those living in the less developed nations, where people appear more liberal in the former and more conservative in the latter. An example of this phenomenon is attitudes towards homosexuality, while 32 out of the 54 African nations criminalise homosexuality, no country in Europe has a law expressly prohibiting homosexual activities. Contrasts in people’s attitudes between the developed and developing world can also be seen in other areas such as religion, premarital sex and even the modesty of female clothing. Additionally, just a century ago most, if not all, of today’s developed nations experienced a high rate of poverty. Back then, people’s mindsets were also what we would today call conservative, a prominent example of which was the prudency of people living in Victorian England. This raises one question: what is the link between the intangible mindsets of people living within a given society and the tangible advancement, or lack thereof, in said society? In order to assess the way humans behave, the most logical place to turn to is the brain. Brain scans have shown that people who self-identify as conservatives have a larger right amygdala; this is the area of the brain responsible for processing fear. This makes sense, given that in poor nations people tend to live in more fear than in their developed counterparts. Even within a developed nation such as the United States, it has been shown that shortly after the events of September 11, there was an increase in conservative leanings with increased support for military spending. If this is the state of a wealthy nation, what would it mean for one where people live fearfully on a day-to-day basis? There are a variety of ways in which the right amygdala, and by extension fear, would affect the way people behave in different countries. For instance, it goes without saying that citizens of conservative countries are traditional and resistant to change. A 2008 study, which catalogued the items in the dormitory rooms of university students, found that liberal-leaning students tended to own more books and travel-related items, which implied their desire for a sense of adventure in their lives. On the other hand, in conservative rooms, there were found to be more items including calendars and cleaning supplies, which were intended to maintain order in their lives. These findings suggest that liberals are more open to more novel experiences, whereas conservatives prefer more order and structure. This could explain the conservative inclination towards familiarity and hence resistance to change. Furthermore, their predisposition towards fear is potentially what makes them more risk-averse and resistant to what is not already an established norm. Many developing countries are also known for their populations’ intolerance across lines of ethnicity, religion or otherwise. A study conducted in 2018 showed that people with more conservative viewpoints were quicker to look away when shown disgusting images - such as vomit, faeces or blood - compared to those with more liberal leanings. From an evolutionary standpoint, this knee-jerk reaction is good for human survival, as this helps to avert potentially harmful pathogens. This quick reaction could also be encouraged by their aforementioned predisposition to fear. However, separate research also suggests that this affects the way in which conservatives view others who are different from themselves, which may explain the affinity towards intolerance in many developing nations. To add to that, this may also explain the negative attitude in such countries towards mental health and people with disabilities, which people perceive as ‘deviating’ from the norm. As far as religion goes, this itself is a factor that seems to differ between economic levels of development. In fact, there is a clear negative correlation between the GDP per capita of a country and the religiosity of its citizens according to a 2009 Gallup survey. This may also be linked to the predisposition towards fear, as religion is seen by many as a means of maintaining feelings of safety and security in the dangerous world around them. From these findings, it can be inferred that the conservative mentality is centred around fear and viewing the world as a dangerous place. There appears to be a tendency for inhabitants of liberal nations to judge those of conservative nations for being overly repressive and restrictive, while the latter judge the former as being immoral and depraved. One could argue, however, that neither side is right or wrong, only people’s brains adapt to the context around them, particularly in the context of fear where the brain tailors itself to aid in its owner’s survival. That having been said, the developed countries of today have only relatively recently seen widespread prosperity amongst their citizens and along with it only recently adopted their liberal ideas in the mainstream. Thus, we may have to wait for many other countries to develop to gauge whether such a correlation truly exists between a society’s physical development and the mentality of its citizens. There may well be one but for now, only time will tell.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">A Tale of Two Pandemics</title>
      <link href="/A-Tale-of-Two-Pandemics" rel="alternate" type="text/html" title="A Tale of Two Pandemics" />
      <published>2021-03-31T00:00:00+00:00</published>
      <updated>2021-03-31T00:00:00+00:00</updated>
      <id>/A-Tale-of-Two-Pandemics</id>
      <content type="html" xml:base="/A-Tale-of-Two-Pandemics">&lt;p&gt;Over the past year, the COVID-19 pandemic has claimed millions of lives, plunged the world economy into a deep crisis, and laid bare the contradictions and injustices that have resulted from a decade of austerity, privatisation and financialisation. Events of such epochal significance often invite comparisons with the past, and with regards to the circumstances in which it emerged and the economic and social disruption which it has caused, COVID-19 can be compared to the Black Death which swept Europe, Asia and North Africa from 1347 to 1351, killing a third of Europe’s population. This article will examine how the devastating spread of both COVID-19 and the Black Death was catalysed by ecological conditions in which disease flourished, analysing how both diseases profoundly altered the economic systems that had given rise to them, and how in both cases, elites sought to protect their precarious positions by utilising coercive State control over dissident populations.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The System Grinds to a Halt&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Both the Black Death and COVID-19 exposed the flaws in the global, interconnected systems of trade and commerce from which they emerged. The Pax Mongolica, which followed the Mongol conquests of Eurasia and ensured relatively peaceful commerce and communication between West and East, would eventually introduce the plague into Europe. Historian William MacNeill writes that Pax Mongolica had&lt;em&gt; “created a territorially vast human web that linked the Mongol headquarters at Karakorum with Kazan and Astrakhan on the Volga, with Caffa in the Crimea, with Khanbaliq in China and with innumerable other caravanserais in between.” &lt;/em&gt;Pax Mongolica lowered the transactional and protective costs of overland trade, guaranteeing the safety of merchants to travel in the regions controlled by the Mongols, and ensuring that Western countries gained commercial and territorial concessions. The free exchange of goods, ideas and technologies from the Far East to Europe also aided the specialisation of the Italian City States, who expanded their trade in the Black Sea region as a result of Mongolian protection.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;However, the spread of the Black Death followed the aforementioned period of sustained urban and commercial growth, significantly accelerated by an ecological breakdown. A group of Norwegian and Swiss researchers discovered a causal link between warm springs and wet summers in the Karakoram mountain ranges on the borders of China and India and the outbreak of the Black Death, as plague-carrying rodents had fled, forcing fleas to latch onto new hosts. The same system which saw Mongol domination over trade routes in Eurasia and the Silk Road, exchanging goods, raw materials and men, soon became the vector for this deadly bacterial infection, as it spread from Central Asia to Europe, introduced to Europe by Genoese merchants from their trading port in Caffa in the Black Sea during 1347. It is estimated that in the next three years, 20 million Europeans died from the Black Death, in addition to 60 million Chinese people.&lt;/p&gt;
&lt;p&gt;COVID-19 too has emerged from a system of global markets and exchange of information, technology and people, driven by ecological conditions conducive to transferring diseases from animals to humans. Rob Wallace and others &lt;a href=&quot;https://monthlyreview.org/2020/05/01/covid-19-and-circuits-of-capital/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;argue&lt;/a&gt; that: &lt;em&gt;“the entirety of the production line is organised around practices that accelerate the evolution of pathogen virulence and subsequent transmission.” &lt;/em&gt;The character of the modern agribusiness system, replete with monocultures and methods of cutting costs that result in multiple livestock species congregating in the same place, such as in a wet market in Wuhan, creates a fertile breeding ground for viruses. The swine and bird influenza outbreaks also had their origins in this agricultural system. Thomas Gillespie, a &amp;nbsp;professor in Emory University’s department of environmental sciences, &lt;a href=&quot;https://www.theguardian.com/environment/2020/mar/18/tip-of-the-iceberg-is-our-destruction-of-nature-responsible-for-covid-19-aoe&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;told&lt;/a&gt; &lt;em&gt;The Guardian &lt;/em&gt;that &lt;em&gt;“Wet markets make a perfect storm for cross-species transmission of pathogens,”&lt;/em&gt; adding: &lt;em&gt;“Whenever you have novel interactions with a range of species in one place, whether that is in a natural environment like a forest or a wet market, you can have a spillover event.”&lt;/em&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Moreover, the “just in time” supply chains that govern food production, with production calculated to meet market demand rather than human need, crashed in the aftermath of COVID-19. Demand shocks led to price hikes and shortages, and lockdowns severely hampered global supply chains, making the logistics for transporting grain supplies extremely difficult. Dairy farmers in Wisconsin, Minnesota and Georgia were &lt;a href=&quot;https://www.npr.org/sections/thesalt/2020/04/03/826006362/food-shortages-nope-too-much-food-in-the-wrong-places&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;forced to throw away thousands of gallons of milk&lt;/a&gt;, and in Florida, vegetable farmers were forced to abandon fields of harvest-ready produce owing to the acceleration of an acute crisis of overproduction. As with the Black Death and feudalism, COVID-19 did not cause the crises of capitalism, but came into being partly as a consequence of them, demonstrating the volatility and uncertainty of global capitalist markets. In the cases of both the Black Death and COVID-19, environmental conditions hastened the spread of diseases whose devastating impacts threatened to bring the existing economic systems to a standstill.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Elites Consolidate Power&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Black Death struck at the heart of the feudal mode of production, undermining the manorial system and dramatically reducing the Lords’ authority over peasants. Feudalism had been steadily declining prior to the outbreak of the plague, as a lack of virgin land to expand into, coupled with the absorption of agricultural surpluses by lords had lowered the productivity of labour and brought the system to its limits. The income of the feudal aristocracy is &lt;a href=&quot;https://www.marxist.com/black-death-pandemic-changed-world.htm&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;estimated&lt;/a&gt; to have fallen by over 20% between 1347 and 1353. The plague acted as a powerful external shock to the system, engendering cataclysmic changes in the economy and increasing the autonomy, productivity and militancy of the peasantry. For example, owing to the dramatic decline in population that the plague caused, the amount of readily available land increased, allowing peasants to free themselves from the threat of expulsion that had once loomed over them, bargaining for higher wages and lower rents. In the century following the Black Death, rent revenue fell at rates of up to 70% throughout Europe, particularly in regions of Normandy and Flanders. In England, wages doubled over the same period.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;As is currently the case in the countries reeling from the impact of COVID-19&lt;strong&gt;,&lt;/strong&gt; the blows that the Black Death caused to the predominant political and economic system were followed by a frantic consolidation of power by the elites. In 1349, Edward III introduced a Statute of Labourers, a failed attempt to fix wages at their pre-plague levels, which stated: “If any...take more wages than were wont to be paid, he shall be committed to gaol.” The following year, the Archbishop of Canterbury denounced the “greed” of peasants who dared to charge extra money for their services. The punitive Poll Tax of 1377, levied in part to finance a war against France, sparked the peasants’ revolt, the memory of which echoed in the riots against the poll tax imposed by Margeret Thatcher centuries later.&lt;/p&gt;
&lt;p&gt;While the attempts to entrench authority and quell dissent in the aftermath of the Black Death involved restricting the autonomy and competitiveness of a new class of independent peasants, the post-COVID world will likely incur the utilisation of modern technologies and bureaucracies to stifle protest and coerce labour. For example, Hungarian Prime Minister Viktor Orban used the COVID crisis as a pretext to pass a controversial Parliamentary bill allowing him to rule by decree with minimal oversight, and Philippines President Rodrigo Duterte awarded himself emergency powers to carry out press censorship.&lt;/p&gt;
&lt;p&gt;Furthermore, the transformation and digitisation of work, coupled with the potential for the retrenchment of surveillance and expansion of the power of&amp;nbsp; Big Tech, pose a significant threat to the freedom of a now-disposable working class. Both the Black Death and COVID-19 accelerated technological developments which constrained the power of a militant workforce. In the aftermath of the Black Death, rising labour costs saw the purchase of improved tools, machinery, fertiliser and other methods of production replacing expensive labour, as capital-intensive industries emerged, stimulating textile industries in Holland and England. The proliferation of online work and the shift away from offices in professional labour as a result of COVID could potentially give employers access to cheaper labour in overseas markets, as employees become easier to replace. This increased labour market flexibility may also be used to stifle dissent and trade union activity.&lt;/p&gt;
&lt;p&gt;The world’s billionaires have made record profits in the aftermath of COVID-19, as Swiss Bank UBS reported that they had increased their wealth by 27.5% between April and July 2020. The collective wealth of America’s 651 billionaires increased by $1 trillion during the pandemic, &lt;a href=&quot;https://americansfortaxfairness.org/wp-content/uploads/12-9-20-National-Billionaires-Report-Press-Release-1T-4T-FINAL-1.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;according&lt;/a&gt; to The Institute for Policy Studies. Owing to the collapse of small businesses as a result of lockdowns and a spike in demand for online retailers like Amazon, the comparative ease with which big business could weather the storm of economic turmoil has facilitated a concentration of wealth not seen since the Vanderbilts, Rockefellers and Carnegies amassed vast fortunes at the end of the 19th century. Global tech companies whose business models are predicated on accruing vast amounts of venture capital and mining consumer data, and as such depend on establishing monopolies to function, have also largely emerged unscathed. In a similar way to how the Black Death catalysed the emergence of a bureaucratic class of merchants on whom the weakened feudal monarchy became increasingly dependent, COVID-19 may propel the modern technocrats of Silicon Valley to even greater heights than are currently conceivable.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The Black Death, and the response to it by political elites, provides an instructive historical case study in how the spread of disease can radically alter the balance of power within a society, drastically revolutionising the productive forces and paving the way for radical change. The response to the Black Death by landlords and feudal aristocrats, which took the form of coercive labour controls and wage reductions, led directly to the peasants’ revolt. The aftermath of COVID-19 has already seen vast corporate payouts and a concentration of wealth alongside a marked upsurge in evictions, homelessness and extreme poverty. To prevent the emergence of ruthless State-monopoly capitalism, it is imperative to learn the lessons of history, which can provide blueprints for building a new society in the shell of the old. &lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Tom Perrett</name>
        
        
      </author>

      

      
        <category term="featured" />
      
        <category term="society" />
      

      
        <summary type="html">Over the past year, the COVID-19 pandemic has claimed millions of lives, plunged the world economy into a deep crisis, and laid bare the contradictions and injustices that have resulted from a decade of austerity, privatisation and financialisation. Events of such epochal significance often invite comparisons with the past, and with regards to the circumstances in which it emerged and the economic and social disruption which it has caused, COVID-19 can be compared to the Black Death which swept Europe, Asia and North Africa from 1347 to 1351, killing a third of Europe’s population. This article will examine how the devastating spread of both COVID-19 and the Black Death was catalysed by ecological conditions in which disease flourished, analysing how both diseases profoundly altered the economic systems that had given rise to them, and how in both cases, elites sought to protect their precarious positions by utilising coercive State control over dissident populations.&amp;nbsp; The System Grinds to a Halt Both the Black Death and COVID-19 exposed the flaws in the global, interconnected systems of trade and commerce from which they emerged. The Pax Mongolica, which followed the Mongol conquests of Eurasia and ensured relatively peaceful commerce and communication between West and East, would eventually introduce the plague into Europe. Historian William MacNeill writes that Pax Mongolica had “created a territorially vast human web that linked the Mongol headquarters at Karakorum with Kazan and Astrakhan on the Volga, with Caffa in the Crimea, with Khanbaliq in China and with innumerable other caravanserais in between.” Pax Mongolica lowered the transactional and protective costs of overland trade, guaranteeing the safety of merchants to travel in the regions controlled by the Mongols, and ensuring that Western countries gained commercial and territorial concessions. The free exchange of goods, ideas and technologies from the Far East to Europe also aided the specialisation of the Italian City States, who expanded their trade in the Black Sea region as a result of Mongolian protection.&amp;nbsp; However, the spread of the Black Death followed the aforementioned period of sustained urban and commercial growth, significantly accelerated by an ecological breakdown. A group of Norwegian and Swiss researchers discovered a causal link between warm springs and wet summers in the Karakoram mountain ranges on the borders of China and India and the outbreak of the Black Death, as plague-carrying rodents had fled, forcing fleas to latch onto new hosts. The same system which saw Mongol domination over trade routes in Eurasia and the Silk Road, exchanging goods, raw materials and men, soon became the vector for this deadly bacterial infection, as it spread from Central Asia to Europe, introduced to Europe by Genoese merchants from their trading port in Caffa in the Black Sea during 1347. It is estimated that in the next three years, 20 million Europeans died from the Black Death, in addition to 60 million Chinese people. COVID-19 too has emerged from a system of global markets and exchange of information, technology and people, driven by ecological conditions conducive to transferring diseases from animals to humans. Rob Wallace and others argue that: “the entirety of the production line is organised around practices that accelerate the evolution of pathogen virulence and subsequent transmission.” The character of the modern agribusiness system, replete with monocultures and methods of cutting costs that result in multiple livestock species congregating in the same place, such as in a wet market in Wuhan, creates a fertile breeding ground for viruses. The swine and bird influenza outbreaks also had their origins in this agricultural system. Thomas Gillespie, a &amp;nbsp;professor in Emory University’s department of environmental sciences, told The Guardian that “Wet markets make a perfect storm for cross-species transmission of pathogens,” adding: “Whenever you have novel interactions with a range of species in one place, whether that is in a natural environment like a forest or a wet market, you can have a spillover event.”&amp;nbsp; Moreover, the “just in time” supply chains that govern food production, with production calculated to meet market demand rather than human need, crashed in the aftermath of COVID-19. Demand shocks led to price hikes and shortages, and lockdowns severely hampered global supply chains, making the logistics for transporting grain supplies extremely difficult. Dairy farmers in Wisconsin, Minnesota and Georgia were forced to throw away thousands of gallons of milk, and in Florida, vegetable farmers were forced to abandon fields of harvest-ready produce owing to the acceleration of an acute crisis of overproduction. As with the Black Death and feudalism, COVID-19 did not cause the crises of capitalism, but came into being partly as a consequence of them, demonstrating the volatility and uncertainty of global capitalist markets. In the cases of both the Black Death and COVID-19, environmental conditions hastened the spread of diseases whose devastating impacts threatened to bring the existing economic systems to a standstill.&amp;nbsp; The Elites Consolidate Power The Black Death struck at the heart of the feudal mode of production, undermining the manorial system and dramatically reducing the Lords’ authority over peasants. Feudalism had been steadily declining prior to the outbreak of the plague, as a lack of virgin land to expand into, coupled with the absorption of agricultural surpluses by lords had lowered the productivity of labour and brought the system to its limits. The income of the feudal aristocracy is estimated to have fallen by over 20% between 1347 and 1353. The plague acted as a powerful external shock to the system, engendering cataclysmic changes in the economy and increasing the autonomy, productivity and militancy of the peasantry. For example, owing to the dramatic decline in population that the plague caused, the amount of readily available land increased, allowing peasants to free themselves from the threat of expulsion that had once loomed over them, bargaining for higher wages and lower rents. In the century following the Black Death, rent revenue fell at rates of up to 70% throughout Europe, particularly in regions of Normandy and Flanders. In England, wages doubled over the same period.&amp;nbsp; As is currently the case in the countries reeling from the impact of COVID-19, the blows that the Black Death caused to the predominant political and economic system were followed by a frantic consolidation of power by the elites. In 1349, Edward III introduced a Statute of Labourers, a failed attempt to fix wages at their pre-plague levels, which stated: “If any...take more wages than were wont to be paid, he shall be committed to gaol.” The following year, the Archbishop of Canterbury denounced the “greed” of peasants who dared to charge extra money for their services. The punitive Poll Tax of 1377, levied in part to finance a war against France, sparked the peasants’ revolt, the memory of which echoed in the riots against the poll tax imposed by Margeret Thatcher centuries later. While the attempts to entrench authority and quell dissent in the aftermath of the Black Death involved restricting the autonomy and competitiveness of a new class of independent peasants, the post-COVID world will likely incur the utilisation of modern technologies and bureaucracies to stifle protest and coerce labour. For example, Hungarian Prime Minister Viktor Orban used the COVID crisis as a pretext to pass a controversial Parliamentary bill allowing him to rule by decree with minimal oversight, and Philippines President Rodrigo Duterte awarded himself emergency powers to carry out press censorship. Furthermore, the transformation and digitisation of work, coupled with the potential for the retrenchment of surveillance and expansion of the power of&amp;nbsp; Big Tech, pose a significant threat to the freedom of a now-disposable working class. Both the Black Death and COVID-19 accelerated technological developments which constrained the power of a militant workforce. In the aftermath of the Black Death, rising labour costs saw the purchase of improved tools, machinery, fertiliser and other methods of production replacing expensive labour, as capital-intensive industries emerged, stimulating textile industries in Holland and England. The proliferation of online work and the shift away from offices in professional labour as a result of COVID could potentially give employers access to cheaper labour in overseas markets, as employees become easier to replace. This increased labour market flexibility may also be used to stifle dissent and trade union activity. The world’s billionaires have made record profits in the aftermath of COVID-19, as Swiss Bank UBS reported that they had increased their wealth by 27.5% between April and July 2020. The collective wealth of America’s 651 billionaires increased by $1 trillion during the pandemic, according to The Institute for Policy Studies. Owing to the collapse of small businesses as a result of lockdowns and a spike in demand for online retailers like Amazon, the comparative ease with which big business could weather the storm of economic turmoil has facilitated a concentration of wealth not seen since the Vanderbilts, Rockefellers and Carnegies amassed vast fortunes at the end of the 19th century. Global tech companies whose business models are predicated on accruing vast amounts of venture capital and mining consumer data, and as such depend on establishing monopolies to function, have also largely emerged unscathed. In a similar way to how the Black Death catalysed the emergence of a bureaucratic class of merchants on whom the weakened feudal monarchy became increasingly dependent, COVID-19 may propel the modern technocrats of Silicon Valley to even greater heights than are currently conceivable.&amp;nbsp; The Black Death, and the response to it by political elites, provides an instructive historical case study in how the spread of disease can radically alter the balance of power within a society, drastically revolutionising the productive forces and paving the way for radical change. The response to the Black Death by landlords and feudal aristocrats, which took the form of coercive labour controls and wage reductions, led directly to the peasants’ revolt. The aftermath of COVID-19 has already seen vast corporate payouts and a concentration of wealth alongside a marked upsurge in evictions, homelessness and extreme poverty. To prevent the emergence of ruthless State-monopoly capitalism, it is imperative to learn the lessons of history, which can provide blueprints for building a new society in the shell of the old.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Relax, AI is Not as Smart as You Think</title>
      <link href="/Relax-AI-is-Not-as-Smart-as-You-Think" rel="alternate" type="text/html" title="Relax, AI is Not as Smart as You Think" />
      <published>2021-03-23T00:00:00+00:00</published>
      <updated>2021-03-23T00:00:00+00:00</updated>
      <id>/Relax-AI-is-Not-as-Smart-as-You-Think</id>
      <content type="html" xml:base="/Relax-AI-is-Not-as-Smart-as-You-Think">&lt;p&gt;Artificial Intelligence (AI) is a term broadly used to describe some innovation that is trying to solve yet another problem. A &lt;a href=&quot;https://www.gov.uk/government/publications/artificial-intelligence-public-awareness-survey&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;survey&lt;/a&gt; by the UK government in 2019 on over 2,400 individuals reported that a good majority know what AI is, but only 12% know a lot about AI. This is no surprise, and the media doesn’t do well to clarify this uncertainty.&lt;/p&gt;
&lt;p&gt;An early definition of AI was proposed by Alan Turing 70 years ago. He described a method to determine if a machine exhibits intelligent behaviour, known as the 'Imitation Game' - a game where an interrogator judges if the responses to their questions are from a human or machine. Unsurprisingly, this is a great definition. However, as technology advances, problems that were once thought of as only solvable by humans have become ‘easily’ solvable by AI, and are no longer classified as AI problems. This paradox is known as the 'AI Effect'.&lt;/p&gt;
&lt;p&gt;Before breaking down some AI that you might have heard of, I want to be clear about something that is very often misunderstood. AI can be grouped into two categories: Logic Programming&lt;em&gt; &lt;/em&gt;(rule-based intelligence) and Machine Learning&lt;em&gt; &lt;/em&gt;(data-driven intelligence). In the former category, the intelligence of the AI is developed by researchers. They would very carefully study the domain of the problem and describe a set of rules and instructions which would best output a solution to the problem. In the latter category, intelligence is learned by AI. The researcher would typically use an existing learning technique on a model with tweakable settings, and apply it to historical data from the domain of the problem. Then the settings of the model which would output the best possible solution to the problem are found based on the data.&lt;/p&gt;
&lt;p&gt;AI in both these categories has garnered a great deal of positive media attention, and rightfully so, but they have attributed to the great misunderstanding of AI that is widespread in society. Two examples of board game matches from the past 25 years apparently exhibit great strides in AI, but are mostly a testament to computing power rather than intelligent behaviour.&lt;/p&gt;
&lt;p&gt;A Logic Programming AI made history in 1997 when IBM’s supercomputer Deep Blue beat the then reigning world champion in a match of chess under standard tournament conditions. Deep Blue follows a set of logical rules to search for the best sequence of moves needed to win, with its prowess coming from its computational speed. At the time, it could evaluate about 200 million chess moves per second (7-12 turns ahead) and its strategy to win could be completely analysed and interpreted by the researchers, i.e. the reason why it made a particular move was fully understood. Although Deep Blue has no practical applications other than playing chess, it proved that AI could outperform human intelligence at a game often associated with requiring high intelligence.&lt;/p&gt;
&lt;p&gt;On a similar problem, a Machine Learning AI made history in 2016 when Google’s AlphaGo beat the 18-time world champion in a match of Go. Go is a far more complicated game than chess and it is arguably the most complex game ever devised. The number of possible moves from each position of a chess game is about 20 whereas a Go game is about 200. A Logic Programming AI would need to evaluate about 60 trillion moves to think just 6 turns ahead, so finding the best sequence of moves needed to win the game would be unfeasible. Google’s researchers used Deep Reinforcement Learning to tackle the problem. This learning technique was developed in the 1980's and stemmed from research into animal psychology. In this case, the AI was initially presented with 100,000 games of Go and, given rewards when it won, it learned how to play the game. It then played against itself millions of times to iteratively get better, until it was better than a world champion Go player. Unfortunately, this intelligent behaviour comes at a cost; it took 3 days to train AlphaGo and it consumed what would usually be $&lt;a href=&quot;https://www.yuzeh.com/data/agz-cost.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;2 million&lt;/a&gt; of Google's computational power.&lt;/p&gt;
&lt;p&gt;In contrast to Deep Blue, the researchers developing AlphaGo didn’t need to have any prior knowledge of the rules of the game. The AI managed to learn the rules of the game and how to win all by itself. This was a feat of general intelligence, but there are some shortcomings to this kind of AI. What exactly has AlphaGo learned and was it worth the cost?&amp;nbsp;&lt;/p&gt;
&lt;p&gt;AlphaGo belongs to a subset of Machine Learning known as Deep Learning (note that the naming of Deep Blue is a coincidence and it is not classified as Deep Learning) which is notorious for requiring a substantial amount of computational power to learn. Deep Learning AIs spend days churning data to learn how to solve a problem. A study on the energy consumption of hardware built for Deep Learning revealed that the learning process can &lt;a href=&quot;https://arxiv.org/abs/1906.02243&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;emit as much carbon&lt;/a&gt; as the lifetime of five midsize sedans. In addition to that, the intelligent behaviour learned is uninterpretable by even the developers themselves, i.e. we will never know why AlphaGo makes a particular move. Maybe this isn’t such a big problem in a game of Go as the results of the AI are phenomenal.&lt;/p&gt;
&lt;p&gt;The use of AI has amazingly made its way into governments and judicial systems, but has also been the centre of criticism from the media and public alike. In 2016, the Wisconsin Supreme Court ruled for judges to use it as an aid to assess the risk of recidivism. Little is understood about COMPAS since it uses trade secrets. This prompted two independent researchers to compare it to the most basic Machine Learning AI (a linear regression), and they found that there was no significant difference; COMPAS does nothing extraordinarily ‘intelligent’. To add insult to injury, an &lt;a href=&quot;https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;investigation&lt;/a&gt; into its risk assessments revealed that there is an inherent bias that favours white people to be classified as low-risk and black people to be classified as high-risk. This is a big concern in Machine Learning which is driven by historical data. If the data itself is inherently biased then the AI learning from it would be biased as well.&lt;/p&gt;
&lt;p&gt;The cherry on top for how AI is misunderstood was seen in Australia; the RoboDebt scheme. In 2016, the Australian government decided to enlist the help of AI to crack down on the abuse of their welfare system and clawback A$1.5 billion in three years. They implemented an automated debt recovery system (a seemingly Logic Programming AI) that was meant to accurately calculate how much a person owed or was owed by the government. Ironically, it has since incurred the Australian government A$1.2 billion in refunds and payouts.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;There were many things wrong with the implementation of the RoboDebt scheme, but let’s look at it from a purely technical standpoint. To this day, there hasn’t been any scrutiny against the AI used. Put simply it did exactly what it was meant to do and nothing more. The human checks and balances that were in place prior to the AI, however, were completely removed and they weren’t replaced. Fundamental errors in the system weren’t caught. In fact, the biggest technical scrutiny was from the way the Australian government averaged income. This was in place much before RoboDebt and its introduction only perpetuated the already existing problem at a rapid rate. Perhaps an AI is only as ‘intelligent’ as the people it is solving a problem for.&lt;/p&gt;
&lt;p&gt;Most of the AI stories that make it to the headlines greatly tip the scales of its perception and propagate misunderstanding in society. A single AI story shouldn’t shape it as a whole as there are many different types of AI - this article has only scratched the surface. Most AI research doesn’t make it to the headlines. However, there are many great applications and use cases of AI which will shape our future, and only when it does will we hear about it.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Kheeran Naidu</name>
        
        
      </author>

      

      
        <category term="trending" />
      
        <category term="society" />
      

      
        <summary type="html">Artificial Intelligence (AI) is a term broadly used to describe some innovation that is trying to solve yet another problem. A survey by the UK government in 2019 on over 2,400 individuals reported that a good majority know what AI is, but only 12% know a lot about AI. This is no surprise, and the media doesn’t do well to clarify this uncertainty. An early definition of AI was proposed by Alan Turing 70 years ago. He described a method to determine if a machine exhibits intelligent behaviour, known as the 'Imitation Game' - a game where an interrogator judges if the responses to their questions are from a human or machine. Unsurprisingly, this is a great definition. However, as technology advances, problems that were once thought of as only solvable by humans have become ‘easily’ solvable by AI, and are no longer classified as AI problems. This paradox is known as the 'AI Effect'. Before breaking down some AI that you might have heard of, I want to be clear about something that is very often misunderstood. AI can be grouped into two categories: Logic Programming (rule-based intelligence) and Machine Learning (data-driven intelligence). In the former category, the intelligence of the AI is developed by researchers. They would very carefully study the domain of the problem and describe a set of rules and instructions which would best output a solution to the problem. In the latter category, intelligence is learned by AI. The researcher would typically use an existing learning technique on a model with tweakable settings, and apply it to historical data from the domain of the problem. Then the settings of the model which would output the best possible solution to the problem are found based on the data. AI in both these categories has garnered a great deal of positive media attention, and rightfully so, but they have attributed to the great misunderstanding of AI that is widespread in society. Two examples of board game matches from the past 25 years apparently exhibit great strides in AI, but are mostly a testament to computing power rather than intelligent behaviour. A Logic Programming AI made history in 1997 when IBM’s supercomputer Deep Blue beat the then reigning world champion in a match of chess under standard tournament conditions. Deep Blue follows a set of logical rules to search for the best sequence of moves needed to win, with its prowess coming from its computational speed. At the time, it could evaluate about 200 million chess moves per second (7-12 turns ahead) and its strategy to win could be completely analysed and interpreted by the researchers, i.e. the reason why it made a particular move was fully understood. Although Deep Blue has no practical applications other than playing chess, it proved that AI could outperform human intelligence at a game often associated with requiring high intelligence. On a similar problem, a Machine Learning AI made history in 2016 when Google’s AlphaGo beat the 18-time world champion in a match of Go. Go is a far more complicated game than chess and it is arguably the most complex game ever devised. The number of possible moves from each position of a chess game is about 20 whereas a Go game is about 200. A Logic Programming AI would need to evaluate about 60 trillion moves to think just 6 turns ahead, so finding the best sequence of moves needed to win the game would be unfeasible. Google’s researchers used Deep Reinforcement Learning to tackle the problem. This learning technique was developed in the 1980's and stemmed from research into animal psychology. In this case, the AI was initially presented with 100,000 games of Go and, given rewards when it won, it learned how to play the game. It then played against itself millions of times to iteratively get better, until it was better than a world champion Go player. Unfortunately, this intelligent behaviour comes at a cost; it took 3 days to train AlphaGo and it consumed what would usually be $2 million of Google's computational power. In contrast to Deep Blue, the researchers developing AlphaGo didn’t need to have any prior knowledge of the rules of the game. The AI managed to learn the rules of the game and how to win all by itself. This was a feat of general intelligence, but there are some shortcomings to this kind of AI. What exactly has AlphaGo learned and was it worth the cost?&amp;nbsp; AlphaGo belongs to a subset of Machine Learning known as Deep Learning (note that the naming of Deep Blue is a coincidence and it is not classified as Deep Learning) which is notorious for requiring a substantial amount of computational power to learn. Deep Learning AIs spend days churning data to learn how to solve a problem. A study on the energy consumption of hardware built for Deep Learning revealed that the learning process can emit as much carbon as the lifetime of five midsize sedans. In addition to that, the intelligent behaviour learned is uninterpretable by even the developers themselves, i.e. we will never know why AlphaGo makes a particular move. Maybe this isn’t such a big problem in a game of Go as the results of the AI are phenomenal. The use of AI has amazingly made its way into governments and judicial systems, but has also been the centre of criticism from the media and public alike. In 2016, the Wisconsin Supreme Court ruled for judges to use it as an aid to assess the risk of recidivism. Little is understood about COMPAS since it uses trade secrets. This prompted two independent researchers to compare it to the most basic Machine Learning AI (a linear regression), and they found that there was no significant difference; COMPAS does nothing extraordinarily ‘intelligent’. To add insult to injury, an investigation into its risk assessments revealed that there is an inherent bias that favours white people to be classified as low-risk and black people to be classified as high-risk. This is a big concern in Machine Learning which is driven by historical data. If the data itself is inherently biased then the AI learning from it would be biased as well. The cherry on top for how AI is misunderstood was seen in Australia; the RoboDebt scheme. In 2016, the Australian government decided to enlist the help of AI to crack down on the abuse of their welfare system and clawback A$1.5 billion in three years. They implemented an automated debt recovery system (a seemingly Logic Programming AI) that was meant to accurately calculate how much a person owed or was owed by the government. Ironically, it has since incurred the Australian government A$1.2 billion in refunds and payouts.&amp;nbsp; There were many things wrong with the implementation of the RoboDebt scheme, but let’s look at it from a purely technical standpoint. To this day, there hasn’t been any scrutiny against the AI used. Put simply it did exactly what it was meant to do and nothing more. The human checks and balances that were in place prior to the AI, however, were completely removed and they weren’t replaced. Fundamental errors in the system weren’t caught. In fact, the biggest technical scrutiny was from the way the Australian government averaged income. This was in place much before RoboDebt and its introduction only perpetuated the already existing problem at a rapid rate. Perhaps an AI is only as ‘intelligent’ as the people it is solving a problem for. Most of the AI stories that make it to the headlines greatly tip the scales of its perception and propagate misunderstanding in society. A single AI story shouldn’t shape it as a whole as there are many different types of AI - this article has only scratched the surface. Most AI research doesn’t make it to the headlines. However, there are many great applications and use cases of AI which will shape our future, and only when it does will we hear about it.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Egyptian Mummies: A Story of the Colonial Abuse of History</title>
      <link href="/Egyptian-Mummies" rel="alternate" type="text/html" title="Egyptian Mummies: A Story of the Colonial Abuse of History" />
      <published>2021-01-29T00:00:00+00:00</published>
      <updated>2021-01-29T00:00:00+00:00</updated>
      <id>/Egyptian-Mummies</id>
      <content type="html" xml:base="/Egyptian-Mummies">&lt;p&gt;Mummies are probably among the most 'Egyptian' things to exist in our history books in spite of the fact that mummification is neither unique to ancient Egypt nor is it always man-made. The main reason behind the popularisation of mummification as a part of ancient Egyptian culture, apart from the academic fascination with the extraordinary methods employed in the process to mummify a dead body by ancient Egyptians, is the endless number of stories that exist about them. Very unsurprisingly, most of them are distorted and sometimes outright lies regarding the culture. Most, if not all of these, are rooted in absolute ignorance about history and sometimes, they exist due to a veiled effort to profit off of an exotic ancient African civilisation.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;As a believer in science and as a passionate reader of history, the process of mummification is rather interesting to me. The Egyptians were, however, not the first to mummify their dead. At least 2,000 years before them, the Chinchorro people of Southern American descent were already practising mummification. Of course, the methods employed vary from civilisation to civilisation. In addition, based on how well the bodies were preserved and other factors, it can be inferred that the procedure changed with time. Unfortunately, climate change has not been kind to mummies. The rising humidity levels have contributed to the spread of flesh-eating microbes, which are detrimental to the preservation of mummies. This makes studying them all the more difficult. Apart from this, the procedure employed for the poor was less extensive compared to that employed for the Pharaohs. Unfortunately, there are no proper accounts of how the mummification was done in ancient Egypt left behind by the Egyptians.&lt;/p&gt;
&lt;p&gt;The only two ancient texts that lay out the mummification techniques are the accounts of Diodorus and Herodotus from when they travelled to Egypt. The famous &lt;em&gt;Book of the Dead&lt;/em&gt;, which has made appearances in various cult classics, does not extensively talk about the methods employed. Instead, it provides various spells and rituals that could potentially help the dead enter the afterlife. In 1994, two scientists used the ancient Egyptian mummification methods on a victim of heart attack successfully, in order to get a greater depth of understanding of the procedure.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The process of mummification is very elaborate. It began with removing the internal organs, with the exception of the heart. The ancient Egyptian religion propagated a belief that the dead were judged by their heart on entering the underworld, before proceeding on to the afterlife. They would thus use an amulet, commonly referred to as the heart scarab, to protect it. The overall mummification process took about 40 days. The Egyptians did not limit this practice to humans - they mummified various animals like cats, ibises, hawks, crocodiles, rats and lizards, primarily for religious reasons.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The practice of mummification in Egypt died out between the 4th and 7th century AD, which is around the time when many of the Egyptians converted to Christianity. It has been estimated that over a period of about 3,000 years over 70 million mummies were made in Egypt. The Egyptian civilisation existed for much longer than this. It is believed that anthropogenic mummification was introduced into practice around 2,600 BC, that is, during the Fourth or Fifth Dynasties. There are older mummies available but these have been preserved naturally, especially owing to the fact that Egypt has zero measurable rainfall.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Egyptian mummies have always fascinated people. While today we are aware of the psyche behind the process and the procedure involved in mummifying the remains of humans, the same cannot be said about those who came much before us and after the decline of ancient Egypt. Scholars of the 18th century were interested in knowing what lay under the wrappings of a mummy. Soon 'Mummy Unwrapping Parties' were popularised by those who could afford them, in their private homes. Later, such unwrapping ceremonies would also be organised in public theatres. Many of these people, who conducted these events, had no knowledge of medical sciences. It was simply a source of entertainment, a way to feed the public’s fascination with mummies and of course, as a symbol of wealth.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;'Mummy dust' makes appearances throughout history in the most absurd places and manners. King Charles II believed that mummy dust could potentially contribute to his greatness and so, he was known to rub it onto his skin. King Francis I of France had a similar belief - he thought that it would make him stronger and so he took a pinch of mummy every day with rhubarb. An abstract published in the &lt;em&gt;Proceedings of the Royal Society of Medicine&lt;/em&gt; journal of 1927 puts forward the idea that between the 12th and the 17th centuries, medicines were prepared from powdered mummies. In fact, 'mummy medicine' was actually very popular around this time and an unrecorded number of mummies were disentombed and burned to prepare the medication. People at the time believed that bitumen had medicinal properties and it was thought that mummification involved embalming the body with bitumen. However, this was actually very uncommon - most mummies were embalmed with resins.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The most commonly encountered occurrence of the Egyptian mummy in popular culture is the undead mummy. Going by Egyptian mythology, this is a rather weird concept. Their religious beliefs encouraged the idea that living beings move on to the after-life after death. A walking mummy in that context is simply absurd. How then was this trope born?&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The mummy genre has its origins in the 19th century. This was when Egypt was first colonised by France and then by Victorian Britain. The colonial romanticisation of the East resulted in most of these early stories, which presented mummies as mostly female and more often than not, the love interest of the protagonist. This is one of the numerous examples of sexualised orientalism born during the age of colonialism. Some of the greatest writers of the age delved into this new genre: &lt;em&gt;The Jewel of the Seven Stars&lt;/em&gt; by Bram Stoker and Sir Arthur Canon Doyle’s &lt;em&gt;The Ring of Thoth&lt;/em&gt; are two such examples. In H D Everett’s &lt;em&gt;Iras: A Mystery&lt;/em&gt;, the protagonist ends up marrying a mummy, which turns into a beautiful woman. In 1845, Edgar Allan Poe wrote &lt;em&gt;Some Words with a Mummy&lt;/em&gt;. This piece was a satire unlike most of the stories about mummies written at the time.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The 1892 novel &lt;em&gt;Lot No. 249&lt;/em&gt;, written by Sir. Doyle is believed to be the first to portray a mummy as a dangerous creature. It was only in the 1930's that the 'monster mummy' started making frequent appearances. The 'romantic mummy' would make a comeback only in the late 20th century with Anne Rice’s 1989 novel, &lt;em&gt;The Mummy, or Ramses the Damned&lt;/em&gt;. This novel, unlike most of the 19th century ones, involved a sexual relationship between a male mummy (instead of a female) and a female archaeologist.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Romanticised and dangerous undead mummies would increasingly dominate books and screens from this point on, in the form of novellas, TV series, video games and so on and so forth. The &lt;em&gt;Goosebumps&lt;/em&gt; series by R L Stine has quite a few of them as monsters. Marvel Comics has its own mummies like N’Kantu. In the very popular &lt;em&gt;Ben 10&lt;/em&gt; franchise, Thep Khufans is a race of alien mummies. The lead character Ben Tennyson has ten alien forms, one of which is Snare-oh, previously named Benmummy, which is a Thep Khufan. In video games, mummies make notable appearances as hostile creatures thriving in deserts in &lt;em&gt;Terraria &lt;/em&gt;and as an immortal creature named Kan-Ra in&lt;em&gt; Killer Instinct&lt;/em&gt;, among others. In several editions of &lt;em&gt;Dungeons and Dragons&lt;/em&gt;, mummies have found a place in the form of Bog Mummies, Hunefers, Mummy Lords, etc. Various films also have Egyptian mummies as characters like Ahkmenrah from the &lt;em&gt;Night at the Museum &lt;/em&gt;and Murray the Mummy from &lt;em&gt;Hotel Transylvania.&lt;/em&gt; Almost nothing in any of these depictions has any similarity with the ancient Egyptian ideas or understanding of mummies and they are simply a result of colonial fascination with oriental culture.&lt;/p&gt;
&lt;p&gt;While walking undead mummies are a creation of the West and have no Egyptian origins, modern science has been trying to make this a reality, at least in a way. DNA capable of being analysed was found in mummies dating back to 2,012 BC by scientists who wish to clone mummies. A group of researchers recreated the voice of a 3,000-year-old mummy of an ancient Egyptian priest, Nesyamun using 3-D printing and body-scanning technology, effectively bringing him to life in 2020. Of course, none of these actually have the effect that the various stories perpetuate - a monster or a lover.&lt;/p&gt;
&lt;p&gt;A common plot in many Egyptian mummy-centric stories of today involves the 'Mummy’s Curse' or the 'Pharaoh’s Curse'. Now the question is, did ancient Egyptians believe in such a curse? The people of ancient Egypt were very particular about protecting tombs and mummies. Many of the pharaohs were entombed in a spot in the famous Valley of the Kings. According to the ancient Egyptian myths, Meretseger, a goddess who took the form of a cobra, protects the Valley of the Kings by blinding or poisoning tomb robbers. There were various punishments put in place to prevent tomb robbery in ancient times. Tomb raiders, who were caught, had the soles of their feet beaten before being publicly impaled on a sharp wooden stick.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Various deaths have been attributed to the Pharaoh’s Curse in the more recent past. The most famous among them is possibly the so-called Curse of Tutankhamun, which is popularly believed to have claimed over six lives in the years following the discovery of the tomb of the boy king in 1922. One of the victims is Lord Carnarvon, the sponsor of the expedition, who died six weeks after the historic event due to supposed blood poisoning. However, Howard Carter, the seemingly prime target of the supposed curses because of the fact that he was responsible for the discovery, died only in 1939, almost 17 years after the opening of the tomb. Only six of the 23 people present during the opening died in a decade following the discovery. With statistics like these, many refuse to believe that a curse was involved in the deaths.&lt;/p&gt;
&lt;p&gt;Many people have tried to explain these deaths. It is commonly believed to be biological in nature. Egyptian tombs have various items intended to help on the dead’s journey to the afterlife, alongside the sarcophagus. This includes food. It is possible that pathogens thrive in such sealed tombs. Investigations into this matter revealed that some tombs have mould-like &lt;em&gt;Aspergillus niger&lt;/em&gt; and &lt;em&gt;Aspergillus flavus&lt;/em&gt;, and bacteria like &lt;em&gt;Pseudomonas&lt;/em&gt; and &lt;em&gt;Staphylococcus&lt;/em&gt;. These are capable of causing various lung ailments. However, most scientists agree that these are not very dangerous. F DeWolfe Miller, Emeritus Professor of Epidemiology at the University of Hawaii at Manoa, agrees with this. He has been quoted as saying that he knows of no archaeologist or tourist who has suffered the adverse effects of tomb toxins.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Howard Carter believed that taking the conditions of Upper Egypt of the 1920's into consideration, Lord Carnarvon was probably safer inside the tomb, a statement that many scientists agree with. In this context, Miller was quoted saying, “The idea that an underground tomb, after 3,000 years, would have some kind of bizarre microorganism in it that's going to kill somebody six weeks later and make it look exactly like [blood poisoning] is very hard to believe”. The cause of the deaths is thus still up for debate.&lt;/p&gt;
&lt;p&gt;The belief in the curses as being the cause has been around for a while now but did they exist back during the ancient times? Late egyptologist Dominic Montserrat was quoted by &lt;em&gt;The Independent&lt;/em&gt; at the conclusion of extensive research into the matter as follows: “My research has not only confirmed that there is, of course, no ancient Egyptian origin of the mummy's curse concept, but, more importantly, it also reveals that it didn't originate in the 1923 press publicity about the discovery of Tutankhamen's tomb either”. The mummy’s curse concept is also not a contribution of Hollywood. In fact, it dates back to the 1800's. One of the earliest examples of this is Louisa May Alcott’s &lt;em&gt;Lost in a Pyramid &lt;/em&gt;or &lt;em&gt;The Mummy’s Curse&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Not all egyptologists agree with this though. Salima Ikram, who is an Egyptologist at the American University of Cairo believes that a form of curses did in fact exist in ancient Egyptian times as a primitive security system against the desecration of the tomb or any form of tomb robbery. According to Ikram, some of the mastaba (early Egyptian non-pyramidal tomb) walls located at Saqqara and Giza have curses inscribed on them. She has been quoted saying, “They tend to threaten desecrators with divine retribution by the council of the gods or a death by crocodiles, or lions, or scorpions, or snakes”.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Due to the expansive availability of various stories regarding the ancient Egyptians, it is difficult to know what among these is actually historically accurate. These stories have had the impact of this ancient civilisation is widely viewed as a land of extremely religious people who practised magic, making it difficult for many, including Elon Musk, to believe that these people built the magnificent pyramids, among other similar astonishing accomplishments. Of course, this is not the first time that Westerners have questioned the capabilities of the people of ancient Asian, South American or African civilisations. Quite frankly, much of what we know today through stories are solely a result of the colonial world’s unhealthy fascination with the exotic cultures and are not rooted in real history. The idea of undead mummies causing devastation or the fact that there are people who are actively seeking to hunt down specific mummies and disentomb them (archaeologists), would probably scandalise the ancient Egyptians. At the end of the day, 'disturbing' the dead in any culture is considered disrespectful. However, people have made exceptions for the ancient Egyptians in the name of gaining knowledge, preparing medicines and sometimes, for the riches enclosed within the walls of the tombs, for a very long time now.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Oindrila Ghosh</name>
        
        
      </author>

      

      
        <category term="society" />
      

      
        <summary type="html">Mummies are probably among the most 'Egyptian' things to exist in our history books in spite of the fact that mummification is neither unique to ancient Egypt nor is it always man-made. The main reason behind the popularisation of mummification as a part of ancient Egyptian culture, apart from the academic fascination with the extraordinary methods employed in the process to mummify a dead body by ancient Egyptians, is the endless number of stories that exist about them. Very unsurprisingly, most of them are distorted and sometimes outright lies regarding the culture. Most, if not all of these, are rooted in absolute ignorance about history and sometimes, they exist due to a veiled effort to profit off of an exotic ancient African civilisation.&amp;nbsp; As a believer in science and as a passionate reader of history, the process of mummification is rather interesting to me. The Egyptians were, however, not the first to mummify their dead. At least 2,000 years before them, the Chinchorro people of Southern American descent were already practising mummification. Of course, the methods employed vary from civilisation to civilisation. In addition, based on how well the bodies were preserved and other factors, it can be inferred that the procedure changed with time. Unfortunately, climate change has not been kind to mummies. The rising humidity levels have contributed to the spread of flesh-eating microbes, which are detrimental to the preservation of mummies. This makes studying them all the more difficult. Apart from this, the procedure employed for the poor was less extensive compared to that employed for the Pharaohs. Unfortunately, there are no proper accounts of how the mummification was done in ancient Egypt left behind by the Egyptians. The only two ancient texts that lay out the mummification techniques are the accounts of Diodorus and Herodotus from when they travelled to Egypt. The famous Book of the Dead, which has made appearances in various cult classics, does not extensively talk about the methods employed. Instead, it provides various spells and rituals that could potentially help the dead enter the afterlife. In 1994, two scientists used the ancient Egyptian mummification methods on a victim of heart attack successfully, in order to get a greater depth of understanding of the procedure.&amp;nbsp; The process of mummification is very elaborate. It began with removing the internal organs, with the exception of the heart. The ancient Egyptian religion propagated a belief that the dead were judged by their heart on entering the underworld, before proceeding on to the afterlife. They would thus use an amulet, commonly referred to as the heart scarab, to protect it. The overall mummification process took about 40 days. The Egyptians did not limit this practice to humans - they mummified various animals like cats, ibises, hawks, crocodiles, rats and lizards, primarily for religious reasons.&amp;nbsp; The practice of mummification in Egypt died out between the 4th and 7th century AD, which is around the time when many of the Egyptians converted to Christianity. It has been estimated that over a period of about 3,000 years over 70 million mummies were made in Egypt. The Egyptian civilisation existed for much longer than this. It is believed that anthropogenic mummification was introduced into practice around 2,600 BC, that is, during the Fourth or Fifth Dynasties. There are older mummies available but these have been preserved naturally, especially owing to the fact that Egypt has zero measurable rainfall.&amp;nbsp; Egyptian mummies have always fascinated people. While today we are aware of the psyche behind the process and the procedure involved in mummifying the remains of humans, the same cannot be said about those who came much before us and after the decline of ancient Egypt. Scholars of the 18th century were interested in knowing what lay under the wrappings of a mummy. Soon 'Mummy Unwrapping Parties' were popularised by those who could afford them, in their private homes. Later, such unwrapping ceremonies would also be organised in public theatres. Many of these people, who conducted these events, had no knowledge of medical sciences. It was simply a source of entertainment, a way to feed the public’s fascination with mummies and of course, as a symbol of wealth.&amp;nbsp; 'Mummy dust' makes appearances throughout history in the most absurd places and manners. King Charles II believed that mummy dust could potentially contribute to his greatness and so, he was known to rub it onto his skin. King Francis I of France had a similar belief - he thought that it would make him stronger and so he took a pinch of mummy every day with rhubarb. An abstract published in the Proceedings of the Royal Society of Medicine journal of 1927 puts forward the idea that between the 12th and the 17th centuries, medicines were prepared from powdered mummies. In fact, 'mummy medicine' was actually very popular around this time and an unrecorded number of mummies were disentombed and burned to prepare the medication. People at the time believed that bitumen had medicinal properties and it was thought that mummification involved embalming the body with bitumen. However, this was actually very uncommon - most mummies were embalmed with resins.&amp;nbsp; The most commonly encountered occurrence of the Egyptian mummy in popular culture is the undead mummy. Going by Egyptian mythology, this is a rather weird concept. Their religious beliefs encouraged the idea that living beings move on to the after-life after death. A walking mummy in that context is simply absurd. How then was this trope born?&amp;nbsp; The mummy genre has its origins in the 19th century. This was when Egypt was first colonised by France and then by Victorian Britain. The colonial romanticisation of the East resulted in most of these early stories, which presented mummies as mostly female and more often than not, the love interest of the protagonist. This is one of the numerous examples of sexualised orientalism born during the age of colonialism. Some of the greatest writers of the age delved into this new genre: The Jewel of the Seven Stars by Bram Stoker and Sir Arthur Canon Doyle’s The Ring of Thoth are two such examples. In H D Everett’s Iras: A Mystery, the protagonist ends up marrying a mummy, which turns into a beautiful woman. In 1845, Edgar Allan Poe wrote Some Words with a Mummy. This piece was a satire unlike most of the stories about mummies written at the time.&amp;nbsp; The 1892 novel Lot No. 249, written by Sir. Doyle is believed to be the first to portray a mummy as a dangerous creature. It was only in the 1930's that the 'monster mummy' started making frequent appearances. The 'romantic mummy' would make a comeback only in the late 20th century with Anne Rice’s 1989 novel, The Mummy, or Ramses the Damned. This novel, unlike most of the 19th century ones, involved a sexual relationship between a male mummy (instead of a female) and a female archaeologist.&amp;nbsp; Romanticised and dangerous undead mummies would increasingly dominate books and screens from this point on, in the form of novellas, TV series, video games and so on and so forth. The Goosebumps series by R L Stine has quite a few of them as monsters. Marvel Comics has its own mummies like N’Kantu. In the very popular Ben 10 franchise, Thep Khufans is a race of alien mummies. The lead character Ben Tennyson has ten alien forms, one of which is Snare-oh, previously named Benmummy, which is a Thep Khufan. In video games, mummies make notable appearances as hostile creatures thriving in deserts in Terraria and as an immortal creature named Kan-Ra in Killer Instinct, among others. In several editions of Dungeons and Dragons, mummies have found a place in the form of Bog Mummies, Hunefers, Mummy Lords, etc. Various films also have Egyptian mummies as characters like Ahkmenrah from the Night at the Museum and Murray the Mummy from Hotel Transylvania. Almost nothing in any of these depictions has any similarity with the ancient Egyptian ideas or understanding of mummies and they are simply a result of colonial fascination with oriental culture. While walking undead mummies are a creation of the West and have no Egyptian origins, modern science has been trying to make this a reality, at least in a way. DNA capable of being analysed was found in mummies dating back to 2,012 BC by scientists who wish to clone mummies. A group of researchers recreated the voice of a 3,000-year-old mummy of an ancient Egyptian priest, Nesyamun using 3-D printing and body-scanning technology, effectively bringing him to life in 2020. Of course, none of these actually have the effect that the various stories perpetuate - a monster or a lover. A common plot in many Egyptian mummy-centric stories of today involves the 'Mummy’s Curse' or the 'Pharaoh’s Curse'. Now the question is, did ancient Egyptians believe in such a curse? The people of ancient Egypt were very particular about protecting tombs and mummies. Many of the pharaohs were entombed in a spot in the famous Valley of the Kings. According to the ancient Egyptian myths, Meretseger, a goddess who took the form of a cobra, protects the Valley of the Kings by blinding or poisoning tomb robbers. There were various punishments put in place to prevent tomb robbery in ancient times. Tomb raiders, who were caught, had the soles of their feet beaten before being publicly impaled on a sharp wooden stick.&amp;nbsp; Various deaths have been attributed to the Pharaoh’s Curse in the more recent past. The most famous among them is possibly the so-called Curse of Tutankhamun, which is popularly believed to have claimed over six lives in the years following the discovery of the tomb of the boy king in 1922. One of the victims is Lord Carnarvon, the sponsor of the expedition, who died six weeks after the historic event due to supposed blood poisoning. However, Howard Carter, the seemingly prime target of the supposed curses because of the fact that he was responsible for the discovery, died only in 1939, almost 17 years after the opening of the tomb. Only six of the 23 people present during the opening died in a decade following the discovery. With statistics like these, many refuse to believe that a curse was involved in the deaths. Many people have tried to explain these deaths. It is commonly believed to be biological in nature. Egyptian tombs have various items intended to help on the dead’s journey to the afterlife, alongside the sarcophagus. This includes food. It is possible that pathogens thrive in such sealed tombs. Investigations into this matter revealed that some tombs have mould-like Aspergillus niger and Aspergillus flavus, and bacteria like Pseudomonas and Staphylococcus. These are capable of causing various lung ailments. However, most scientists agree that these are not very dangerous. F DeWolfe Miller, Emeritus Professor of Epidemiology at the University of Hawaii at Manoa, agrees with this. He has been quoted as saying that he knows of no archaeologist or tourist who has suffered the adverse effects of tomb toxins.&amp;nbsp; Howard Carter believed that taking the conditions of Upper Egypt of the 1920's into consideration, Lord Carnarvon was probably safer inside the tomb, a statement that many scientists agree with. In this context, Miller was quoted saying, “The idea that an underground tomb, after 3,000 years, would have some kind of bizarre microorganism in it that's going to kill somebody six weeks later and make it look exactly like [blood poisoning] is very hard to believe”. The cause of the deaths is thus still up for debate. The belief in the curses as being the cause has been around for a while now but did they exist back during the ancient times? Late egyptologist Dominic Montserrat was quoted by The Independent at the conclusion of extensive research into the matter as follows: “My research has not only confirmed that there is, of course, no ancient Egyptian origin of the mummy's curse concept, but, more importantly, it also reveals that it didn't originate in the 1923 press publicity about the discovery of Tutankhamen's tomb either”. The mummy’s curse concept is also not a contribution of Hollywood. In fact, it dates back to the 1800's. One of the earliest examples of this is Louisa May Alcott’s Lost in a Pyramid or The Mummy’s Curse. Not all egyptologists agree with this though. Salima Ikram, who is an Egyptologist at the American University of Cairo believes that a form of curses did in fact exist in ancient Egyptian times as a primitive security system against the desecration of the tomb or any form of tomb robbery. According to Ikram, some of the mastaba (early Egyptian non-pyramidal tomb) walls located at Saqqara and Giza have curses inscribed on them. She has been quoted saying, “They tend to threaten desecrators with divine retribution by the council of the gods or a death by crocodiles, or lions, or scorpions, or snakes”.&amp;nbsp; Due to the expansive availability of various stories regarding the ancient Egyptians, it is difficult to know what among these is actually historically accurate. These stories have had the impact of this ancient civilisation is widely viewed as a land of extremely religious people who practised magic, making it difficult for many, including Elon Musk, to believe that these people built the magnificent pyramids, among other similar astonishing accomplishments. Of course, this is not the first time that Westerners have questioned the capabilities of the people of ancient Asian, South American or African civilisations. Quite frankly, much of what we know today through stories are solely a result of the colonial world’s unhealthy fascination with the exotic cultures and are not rooted in real history. The idea of undead mummies causing devastation or the fact that there are people who are actively seeking to hunt down specific mummies and disentomb them (archaeologists), would probably scandalise the ancient Egyptians. At the end of the day, 'disturbing' the dead in any culture is considered disrespectful. However, people have made exceptions for the ancient Egyptians in the name of gaining knowledge, preparing medicines and sometimes, for the riches enclosed within the walls of the tombs, for a very long time now.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">The One Time You Shouldn’t Be Appropriate</title>
      <link href="/The-One-Time-You-Shouldn-t-Be-Appropriate" rel="alternate" type="text/html" title="The One Time You Shouldn't Be Appropriate" />
      <published>2021-01-11T00:00:00+00:00</published>
      <updated>2021-01-11T00:00:00+00:00</updated>
      <id>/The-One-Time-You-Shouldn-t-Be-Appropriate</id>
      <content type="html" xml:base="/The-One-Time-You-Shouldn-t-Be-Appropriate">&lt;p&gt;Jack Skellington, uninspired, and in a rut, discovers Christmas Town, falls head over heels with a culture that is not his to begin with, does not talk to a single person who actually lives there, and thus fails to understand the significance of its elements, then goes on to falsify their image in order to appeal to a different audience, and despite their reluctance, decides that he, the Pumpkin King of Halloweentown, can in fact do Christmas better than Christmas Town. At which he fails. Spectacularly.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Unlike what John Mulaney would say, we, dear readers, absolutely do have the time to unpack all of that.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;Nightmare Before Christmas&lt;/em&gt; (1993) is an excellent conversation starter and explanation tool if you are completely new to the concept of cultural appropriation. The &lt;em&gt;Cambridge Dictionary&lt;/em&gt; defines cultural appropriation as “&lt;em&gt;the&amp;nbsp;&lt;/em&gt;&lt;a href=&quot;https://dictionary.cambridge.org/dictionary/english/act&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;act&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&amp;nbsp;of taking or using things from a&amp;nbsp;&lt;/em&gt;&lt;a href=&quot;https://dictionary.cambridge.org/dictionary/english/culture&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;culture&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&amp;nbsp;that is not&amp;nbsp;&lt;/em&gt;&lt;a href=&quot;https://dictionary.cambridge.org/dictionary/english/your&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;your&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&amp;nbsp;own,&amp;nbsp;&lt;/em&gt;&lt;a href=&quot;https://dictionary.cambridge.org/dictionary/english/especially&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;especially&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&amp;nbsp;without&amp;nbsp;&lt;/em&gt;&lt;a href=&quot;https://dictionary.cambridge.org/dictionary/english/showing&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;showing&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&amp;nbsp;that you&amp;nbsp;&lt;/em&gt;&lt;a href=&quot;https://dictionary.cambridge.org/dictionary/english/understand&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;understand&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&amp;nbsp;or&amp;nbsp;&lt;/em&gt;&lt;a href=&quot;https://dictionary.cambridge.org/dictionary/english/respect&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;respect&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&amp;nbsp;the original&amp;nbsp;&lt;/em&gt;&lt;a href=&quot;https://dictionary.cambridge.org/dictionary/english/culture&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;culture&lt;/em&gt;&lt;/a&gt;&lt;em&gt;.&lt;/em&gt;”&lt;/p&gt;
&lt;p&gt;As the story begins, Jack is shown disheartened with the usual Halloween festivities – as he leads the celebration each year, he privately grows weary of it. Thus, it is an extremely delightful experience for him when he discovers the even gates representing different festivals – and goes through the one leading to the Christmas Town. He discovers a brand new world, a different festival, and a wildly different way of living. Enthused, he takes back some of the things he likes (Christmas baubles, candy canes, etc.) in an attempt to understand what it was that made Christmas so magical. Notice how he doesn’t even try to talk to the residents of the town, who would have answered his questions in depth had he just thought to ask. The residents of Halloween Town are also confused, since without any context as to why things are done a certain way, all the Christmas elements can only be compared to what they already know, and do not come at par. As expected, Jack fails at understanding Christmas because even after the multiple experiments and equations back at his crib, he is, after all, using his egregiously narrow perspective to explain something totally out of his scope.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;When Jack can neither understand nor rationally explain Christmas to anyone – not even to himself, he simply decides that he is going to ‘improve Christmas’ as it is unfair that only Christmas Town gets to celebrate it. He tasks different citizens with jobs like ‘singing carols’, ‘preparing gifts’ and even ‘kidnapping Santa’ to make sure he is fully prepared to lead the festivities. Despite getting warned not to proceed, Jack goes on to botch the entire festival, ruin Christmas for the normal world, and as a return gift, gets shot out of the sky.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;A key fact about cultural appropriation that is missing from the above story is that it is always people of the dominant culture that appropriate the culture of the minorities. While Christmas is in no way a ‘minority culture’ – the &lt;em&gt;Nightmare before Christmas&lt;/em&gt; serves some excellent points in what not to do when taking inspiration from another culture.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Why is cultural appropriation a problem? What is so wrong in getting influenced by another culture, especially in a world where there is increased access to everything that exists on earth? The problem arises when the ‘influence’ and ‘inspiration’ is taken for the wrong reasons. When white musicians use music pioneered by black artists and make a killing off of it, when fashion houses host shows inspired by black culture but have only white people modelling for them, or when white people dress up as geishas or put tribal paint on for Halloween – that is when they cross the line from appreciation to appropriation. It is problematic when artists like Zendaya get ridiculed for wearing dreadlocks (which is a common hairstyle for people of African ethnicities) while white celebrities like many of the Kardashian – Jenners continue to do the same and garner millions of Instagram likes and shares despite significant backlash from the black community.&lt;/p&gt;
&lt;p&gt;As an Indian, I am not new to watching my culture get appropriated for profit or aesthetic, even though every new instance in an apparently increasingly educated world does make me infuriated. Music festivals are a breeding ground for not just STDs, but also for blatant disrespect of ‘exotic’ cultures, as white people wear bindis, apply henna, or get dressed in the traditional garb of other cultures, all for the aesthetic. While doing the same in normal settings would lead to immense amounts of ridicule not to the white person, but to the Indian just trying to wear something common in their community. White people may profit hugely and be seen as ‘cool’ from doing the same things that people of colour have been doing since long. Even many K-pop artists have remorselessly appropriated different cultures – from randomly wearing dreadlocks in rap videos, to the girl group Blackpink most recently using a statue of the Hindu god Ganesha in an unrelated music video, no amount of fan led educational discourse seems to stop them in their tracks.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Cultural appropriation does more than harm the sentiments of the non-dominant community. It perpetuates offensive stereotypes, and may blind people to the true origins of the culture being appropriated. When Miley Cyrus famously twerked in her ‘We Can’t Stop’ music video – generations of people formed the misconception that it was she who had invented the dance move rather than African-American artists from New Orleans in the early 1990's. This kind of appropriation also opens the gate to fetishisation of concepts not meant to be sexual – the glaring popularity of ‘sexy kimono’ or ‘sexy geisha outfit’ searches during Halloween in America is a testament to this very fact. Kimono is the traditional dress of the Japanese woman, with a rich history that does not deserve to be reduced to a costume for an entitled brat. And geishas have a long history of being dignified artists and performers, not some sort of glorified sex workers. In fact, the entire premise of Halloween is based on appropriation– the people who most fervently celebrate it remain ignorant of its roots, using it as an excuse to wear costumes that degrade cultures different from them. The ancient Samhain tradition of wearing masks to scare away evil spirits has devolved into misogynistic and appropriative debauchery for the amusement of many.&lt;/p&gt;
&lt;p&gt;Using elements of a different culture merely ‘for the aesthetic’ and because you apparently can’t think of something original – cultural appropriation is, in a nutshell, plagiarism of the oppressed. And in a world where Google can be opened on nearly any electronic device, there is no excuse for anyone to remain ignorant of the culture they are supposedly being inspired by.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Swati Mathuria</name>
        
        
      </author>

      

      
        <category term="society" />
      

      
        <summary type="html">Jack Skellington, uninspired, and in a rut, discovers Christmas Town, falls head over heels with a culture that is not his to begin with, does not talk to a single person who actually lives there, and thus fails to understand the significance of its elements, then goes on to falsify their image in order to appeal to a different audience, and despite their reluctance, decides that he, the Pumpkin King of Halloweentown, can in fact do Christmas better than Christmas Town. At which he fails. Spectacularly.&amp;nbsp;&amp;nbsp; Unlike what John Mulaney would say, we, dear readers, absolutely do have the time to unpack all of that.&amp;nbsp; The Nightmare Before Christmas (1993) is an excellent conversation starter and explanation tool if you are completely new to the concept of cultural appropriation. The Cambridge Dictionary defines cultural appropriation as “the&amp;nbsp;act&amp;nbsp;of taking or using things from a&amp;nbsp;culture&amp;nbsp;that is not&amp;nbsp;your&amp;nbsp;own,&amp;nbsp;especially&amp;nbsp;without&amp;nbsp;showing&amp;nbsp;that you&amp;nbsp;understand&amp;nbsp;or&amp;nbsp;respect&amp;nbsp;the original&amp;nbsp;culture.” As the story begins, Jack is shown disheartened with the usual Halloween festivities – as he leads the celebration each year, he privately grows weary of it. Thus, it is an extremely delightful experience for him when he discovers the even gates representing different festivals – and goes through the one leading to the Christmas Town. He discovers a brand new world, a different festival, and a wildly different way of living. Enthused, he takes back some of the things he likes (Christmas baubles, candy canes, etc.) in an attempt to understand what it was that made Christmas so magical. Notice how he doesn’t even try to talk to the residents of the town, who would have answered his questions in depth had he just thought to ask. The residents of Halloween Town are also confused, since without any context as to why things are done a certain way, all the Christmas elements can only be compared to what they already know, and do not come at par. As expected, Jack fails at understanding Christmas because even after the multiple experiments and equations back at his crib, he is, after all, using his egregiously narrow perspective to explain something totally out of his scope.&amp;nbsp; When Jack can neither understand nor rationally explain Christmas to anyone – not even to himself, he simply decides that he is going to ‘improve Christmas’ as it is unfair that only Christmas Town gets to celebrate it. He tasks different citizens with jobs like ‘singing carols’, ‘preparing gifts’ and even ‘kidnapping Santa’ to make sure he is fully prepared to lead the festivities. Despite getting warned not to proceed, Jack goes on to botch the entire festival, ruin Christmas for the normal world, and as a return gift, gets shot out of the sky.&amp;nbsp; A key fact about cultural appropriation that is missing from the above story is that it is always people of the dominant culture that appropriate the culture of the minorities. While Christmas is in no way a ‘minority culture’ – the Nightmare before Christmas serves some excellent points in what not to do when taking inspiration from another culture.&amp;nbsp; Why is cultural appropriation a problem? What is so wrong in getting influenced by another culture, especially in a world where there is increased access to everything that exists on earth? The problem arises when the ‘influence’ and ‘inspiration’ is taken for the wrong reasons. When white musicians use music pioneered by black artists and make a killing off of it, when fashion houses host shows inspired by black culture but have only white people modelling for them, or when white people dress up as geishas or put tribal paint on for Halloween – that is when they cross the line from appreciation to appropriation. It is problematic when artists like Zendaya get ridiculed for wearing dreadlocks (which is a common hairstyle for people of African ethnicities) while white celebrities like many of the Kardashian – Jenners continue to do the same and garner millions of Instagram likes and shares despite significant backlash from the black community. As an Indian, I am not new to watching my culture get appropriated for profit or aesthetic, even though every new instance in an apparently increasingly educated world does make me infuriated. Music festivals are a breeding ground for not just STDs, but also for blatant disrespect of ‘exotic’ cultures, as white people wear bindis, apply henna, or get dressed in the traditional garb of other cultures, all for the aesthetic. While doing the same in normal settings would lead to immense amounts of ridicule not to the white person, but to the Indian just trying to wear something common in their community. White people may profit hugely and be seen as ‘cool’ from doing the same things that people of colour have been doing since long. Even many K-pop artists have remorselessly appropriated different cultures – from randomly wearing dreadlocks in rap videos, to the girl group Blackpink most recently using a statue of the Hindu god Ganesha in an unrelated music video, no amount of fan led educational discourse seems to stop them in their tracks.&amp;nbsp; Cultural appropriation does more than harm the sentiments of the non-dominant community. It perpetuates offensive stereotypes, and may blind people to the true origins of the culture being appropriated. When Miley Cyrus famously twerked in her ‘We Can’t Stop’ music video – generations of people formed the misconception that it was she who had invented the dance move rather than African-American artists from New Orleans in the early 1990's. This kind of appropriation also opens the gate to fetishisation of concepts not meant to be sexual – the glaring popularity of ‘sexy kimono’ or ‘sexy geisha outfit’ searches during Halloween in America is a testament to this very fact. Kimono is the traditional dress of the Japanese woman, with a rich history that does not deserve to be reduced to a costume for an entitled brat. And geishas have a long history of being dignified artists and performers, not some sort of glorified sex workers. In fact, the entire premise of Halloween is based on appropriation– the people who most fervently celebrate it remain ignorant of its roots, using it as an excuse to wear costumes that degrade cultures different from them. The ancient Samhain tradition of wearing masks to scare away evil spirits has devolved into misogynistic and appropriative debauchery for the amusement of many. Using elements of a different culture merely ‘for the aesthetic’ and because you apparently can’t think of something original – cultural appropriation is, in a nutshell, plagiarism of the oppressed. And in a world where Google can be opened on nearly any electronic device, there is no excuse for anyone to remain ignorant of the culture they are supposedly being inspired by.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Virtual Classrooms and Open Book Examinations</title>
      <link href="/Virtual-Classrooms-and-Open-Book-Examinations" rel="alternate" type="text/html" title="Virtual Classrooms and Open Book Examinations" />
      <published>2020-12-12T00:00:00+00:00</published>
      <updated>2020-12-12T00:00:00+00:00</updated>
      <id>/Virtual-Classrooms-and-Open-Book-Examinations</id>
      <content type="html" xml:base="/Virtual-Classrooms-and-Open-Book-Examinations">&lt;p&gt;Virtual classrooms is a phrase that has become an important part of the new normal, and along with it comes the infamous open-book examinations. Who would have thought that in 2020, the mainstream physical examinations would be replaced by open book examinations. But then again, who in their wildest dreams would have thought that the whole world will be stuck inside their homes, or away from it, for almost a year. The pandemic has clearly uprooted the lives of many, and the students, all across the globe, are no different.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Students have been forced to stay within the four walls of their houses, and attend digital schooling. In a country like India or the UK, it was March or April when the lockdown started as a result of the pandemic, and honestly, at that time no one thought it would go on for this long. In fact, no one was prepared for this pandemic and surely wasn’t ready to adapt to it.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;It was clear from the start that the educational institutions were going to make decisions that might not be suited for the heterogeneous society that we are. Too many debates, discussions and uncertainty led to all sorts of discussions on what to do for the students who had their exams approaching. Thus, emerged the idea of open-book examinations for final year college students. This was initially taken up by Delhi University. The exams got postponed so many times that by the time we took the test we had lost the count. But when these examinations did take place, they happened at a definite, not-so-unclear cost.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;You see, as a person, who could afford to have a separate room and a laptop to take the exams in peace, I was still drowned in intense amounts of anxiety. For, as a student since the past 17 years, all I had to focus on was my paper. Anything from a wrong question, to doubts, to submission of sheets was to be taken care of by the invigilators. The usage of any sort of technology wasn't even a part of the discussion. So these 17 years taught me to dedicate my whole three hours to write the exam. But with this pandemic and open-book examinations, it meant that for once I was required to do all the tasks by myself, using technology, an approach that many of us were clueless about, the added stress being whether the sheets were being uploaded and were the scanned images even clear. All this made me wonder about those who did not have all these layers of privilege I had, and the added stress levels they had to deal with. Obviously, by no means can I even come close to understanding how dreadful all this would have been for them.&lt;/p&gt;
&lt;p&gt;It is in times like these where the only source of interaction and schooling is through technology, people are forced to be left out, just because they cannot afford such a luxury. Thus, in such situations, something like education that we consider a necessity, in fact, becomes a luxury for many people.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Since the past few months, all the classes are being taken online. Within the span of these months, the mode of examinations has expanded to become MCQ-based or assignment-based. Despite all of this, looking at the state of students, it all doesn't look so different from the idea of a zero academic year, which many people find absurd. The students are constantly stuck onto the screens to study and then to do their homework and assignments, no wonder they are so tired from it all. From teachers figuring out how to make it all understandable to a class with no video and microphone on, to the students attending the class but sleeping through most of it. There is little to no education taking place.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;All of this seems like it was bound to happen because our teaching methods have been developed for face-to-face interactions and not for video-call sessions. Moreover, Indian education systems aren't even reformed enough to focus on teaching the concepts, rather than focusing on exams, which clearly doesn't sit well with the condition we are in currently. Hence, it really makes no sense to have open-book examinations or any form of virtual examinations for that matter, when our whole education system is based on seeing how well you remember what you have learnt, and not really how well you grasp the concept.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The pandemic has already increased our anxiety levels, and an education like this just adds to it all. This is only the state of the ones who are privileged enough to actually have access to such resources and means of education. There are so many students out there who due to different reasons cannot take up online classes. And hence have no other option but to skip this year, in the hopes that they'll get to join next year. No one can imagine the stress of these children and the huge loss to their mental health as a result of not being able to take up classes this year. We did see one such incident come forth from Lady Shri Ram College, Delhi University, where a brilliant student was so burdened by the stress of her family's financial incapability that it made her take her own life. It was only then that the college decided to take action towards reducing fees and providing help to those in need. But is it really the lack of financial capability of the family, or the lack of concern of the people sitting on the other end, who refuse to look into how the pandemic could be affecting the students and their families?&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Looking around we do see differences when it comes to how the private institutions and government institutions have dealt with digital schooling. And definitely, there is a clear difference between nations across the globe. However, despite these differences, with some institutions clearly having a better grasp of virtual classroom systems, none of the institutions were prepared to shift their entire curriculum fully online for a whole year, or maybe even more. And even though, for once I am willing to believe that all the educational institutions took the most suitable option in the current scenario, there are still aspects which they just chose to ignore. While they adapted to the new normal, they forgot to look into the students who too had to adapt to it. From lack of concern towards the cash crunch that people are facing, to the effects of the pandemic on the mental and physical well-being of students — all of this is far from being discussed. There are still students left who haven't taken examinations due to various reasons, and they are constantly under stress, with the uncertainty of when they'll actually take them only growing. Every day my Instagram stories are filled with students crying over the extensive amount of pressure from the deadlines of assignments and the upcoming exams.&lt;/p&gt;
&lt;p&gt;All of this makes us wonder what is the point of such an education that only focuses on finishing the curriculum and not even on making sure that each and every student is actually able to attend these classes. Even if it seems that digital schooling is the only possible option right now, is it really worth it if it is at the expense of the sanity of the students, especially with so many students being left out of it altogether?&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Priyanshi Mehra</name>
        
        
      </author>

      

      
        <category term="society" />
      

      
        <summary type="html">Virtual classrooms is a phrase that has become an important part of the new normal, and along with it comes the infamous open-book examinations. Who would have thought that in 2020, the mainstream physical examinations would be replaced by open book examinations. But then again, who in their wildest dreams would have thought that the whole world will be stuck inside their homes, or away from it, for almost a year. The pandemic has clearly uprooted the lives of many, and the students, all across the globe, are no different.&amp;nbsp; Students have been forced to stay within the four walls of their houses, and attend digital schooling. In a country like India or the UK, it was March or April when the lockdown started as a result of the pandemic, and honestly, at that time no one thought it would go on for this long. In fact, no one was prepared for this pandemic and surely wasn’t ready to adapt to it.&amp;nbsp; It was clear from the start that the educational institutions were going to make decisions that might not be suited for the heterogeneous society that we are. Too many debates, discussions and uncertainty led to all sorts of discussions on what to do for the students who had their exams approaching. Thus, emerged the idea of open-book examinations for final year college students. This was initially taken up by Delhi University. The exams got postponed so many times that by the time we took the test we had lost the count. But when these examinations did take place, they happened at a definite, not-so-unclear cost.&amp;nbsp; You see, as a person, who could afford to have a separate room and a laptop to take the exams in peace, I was still drowned in intense amounts of anxiety. For, as a student since the past 17 years, all I had to focus on was my paper. Anything from a wrong question, to doubts, to submission of sheets was to be taken care of by the invigilators. The usage of any sort of technology wasn't even a part of the discussion. So these 17 years taught me to dedicate my whole three hours to write the exam. But with this pandemic and open-book examinations, it meant that for once I was required to do all the tasks by myself, using technology, an approach that many of us were clueless about, the added stress being whether the sheets were being uploaded and were the scanned images even clear. All this made me wonder about those who did not have all these layers of privilege I had, and the added stress levels they had to deal with. Obviously, by no means can I even come close to understanding how dreadful all this would have been for them. It is in times like these where the only source of interaction and schooling is through technology, people are forced to be left out, just because they cannot afford such a luxury. Thus, in such situations, something like education that we consider a necessity, in fact, becomes a luxury for many people.&amp;nbsp; Since the past few months, all the classes are being taken online. Within the span of these months, the mode of examinations has expanded to become MCQ-based or assignment-based. Despite all of this, looking at the state of students, it all doesn't look so different from the idea of a zero academic year, which many people find absurd. The students are constantly stuck onto the screens to study and then to do their homework and assignments, no wonder they are so tired from it all. From teachers figuring out how to make it all understandable to a class with no video and microphone on, to the students attending the class but sleeping through most of it. There is little to no education taking place.&amp;nbsp; All of this seems like it was bound to happen because our teaching methods have been developed for face-to-face interactions and not for video-call sessions. Moreover, Indian education systems aren't even reformed enough to focus on teaching the concepts, rather than focusing on exams, which clearly doesn't sit well with the condition we are in currently. Hence, it really makes no sense to have open-book examinations or any form of virtual examinations for that matter, when our whole education system is based on seeing how well you remember what you have learnt, and not really how well you grasp the concept.&amp;nbsp; The pandemic has already increased our anxiety levels, and an education like this just adds to it all. This is only the state of the ones who are privileged enough to actually have access to such resources and means of education. There are so many students out there who due to different reasons cannot take up online classes. And hence have no other option but to skip this year, in the hopes that they'll get to join next year. No one can imagine the stress of these children and the huge loss to their mental health as a result of not being able to take up classes this year. We did see one such incident come forth from Lady Shri Ram College, Delhi University, where a brilliant student was so burdened by the stress of her family's financial incapability that it made her take her own life. It was only then that the college decided to take action towards reducing fees and providing help to those in need. But is it really the lack of financial capability of the family, or the lack of concern of the people sitting on the other end, who refuse to look into how the pandemic could be affecting the students and their families?&amp;nbsp; Looking around we do see differences when it comes to how the private institutions and government institutions have dealt with digital schooling. And definitely, there is a clear difference between nations across the globe. However, despite these differences, with some institutions clearly having a better grasp of virtual classroom systems, none of the institutions were prepared to shift their entire curriculum fully online for a whole year, or maybe even more. And even though, for once I am willing to believe that all the educational institutions took the most suitable option in the current scenario, there are still aspects which they just chose to ignore. While they adapted to the new normal, they forgot to look into the students who too had to adapt to it. From lack of concern towards the cash crunch that people are facing, to the effects of the pandemic on the mental and physical well-being of students — all of this is far from being discussed. There are still students left who haven't taken examinations due to various reasons, and they are constantly under stress, with the uncertainty of when they'll actually take them only growing. Every day my Instagram stories are filled with students crying over the extensive amount of pressure from the deadlines of assignments and the upcoming exams. All of this makes us wonder what is the point of such an education that only focuses on finishing the curriculum and not even on making sure that each and every student is actually able to attend these classes. Even if it seems that digital schooling is the only possible option right now, is it really worth it if it is at the expense of the sanity of the students, especially with so many students being left out of it altogether?</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Retail Binge for the Mental Twinge</title>
      <link href="/Retail-Binge-for-the-Mental-Twinge" rel="alternate" type="text/html" title="Retail Binge for the Mental Twinge" />
      <published>2020-12-03T00:00:00+00:00</published>
      <updated>2020-12-03T00:00:00+00:00</updated>
      <id>/Retail-Binge-for-the-Mental-Twinge</id>
      <content type="html" xml:base="/Retail-Binge-for-the-Mental-Twinge">&lt;p class=&quot;ql-align-justify&quot;&gt;They say, “When the going gets tough, the tough go shopping.” This is more commonly known as &lt;em&gt;Retail Therapy&lt;/em&gt;. It is a phenomenon where people shop to improve one’s disposition and raise spirits. People in distress often resort to this as a source of solace. A study published in the journal &lt;em&gt;Psychology and Marketing&lt;/em&gt; states that retail therapy has a lasting positive effect on mood. While its findings pointed out that these are impulsive purchases, the survey suggested that feelings of guilt or regret were not associated among the respondents.&amp;nbsp;The name in itself is ironic. Shopping is a concept deeply rooted in materialism. As its positive impact is temporary, it does not qualify as a ‘therapy’ in the medical sense. However, it is a fairly popular phrase used around the world.&amp;nbsp;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;In a 2001 survey conducted by the European Union, it was found that 33% of the shoppers surveyed had a “high level of addiction to rash buying”. The study also revealed that ‘binge purchasing’ was most common among the Scottish youth. Another study of 1,000 American adults, conducted in 2013, detected that more than half of the respondents indulged in retail therapy. It also threw light on the gender aspect of the practice, stating that it is more common among women than men. It was found that 64.9% of women and 38.9% of men binge purchased while women mostly bought clothing, men indulged in ‘comfort food’. This was further reinforced by the Youngstown State University with similar male-female percentages, showing that relief from stress was the most common reason behind the practice. A more adverse extension of retail therapy is Oniomania or Compulsive Buying Disorder, which is an obsession with shopping, resulting in serious financial and mental consequences.&amp;nbsp;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;&lt;strong&gt;The Whys behind the Comfort Buys&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;While stress, anxiety and sadness are a part of daily life, they can be tackled through other means such as reaching out to others, practicing yoga, mindfulness and meditation, journaling, exercising and consulting experts in more severe cases. Despite there being these solutions, which on an average are cheaper than shopping, why do people indulge in purchasing things to boost their mood? To understand the causes behind retail therapy, the behavioral aspect of individuals needs to be analysed in a twofold manner. Even though, at first glance, these reasons seem simple — associated with daily life, a deeper analysis suggests that the root cause can be traced back to psychological theory.&amp;nbsp;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;Firstly, we examine the relatively straightforward causes.&amp;nbsp;&amp;nbsp;When everything goes wrong and nothing falls into place as you imagined it to, how do you feel? Out of control, right? Thus, one of the reasons people indulge in retail therapy is that shopping is a coping mechanism that helps people feel more in control. From deciding where to shop, to choosing what to purchase, it allows people to exercise autonomy and make decisions. In my personal opinion, shopping can also make one feel a sense of achievement. Utilising good offers and deals, applying coupons to get discounts and sometimes even getting goods for free certainly makes one feel happier as they ‘save’ along with fulfilling a guilty pleasure.&amp;nbsp;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;Secondly, retail therapy can be a useful mechanism for smooth transitions of life as it enables people to envisage their lives post such changes. For instance, people often shop excessively before they are going to live alone for the first time, shifting to a new house, getting married or having a baby. Shopping may ease anxiety by making people feel more in control by helping them to prepare themselves for such huge transitions through the process of ‘visualisation’, which is a process that boosts performance, confidence and reduces anxiety.&amp;nbsp;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;Another way in which retail therapy boosts mood is through a pleasant gush of creativity. Specifically, clothing of various kinds of colors and textures, accessories like jewelry, footwear, bags, sunglasses, etc, home decor items may induce a positive breeze of art and aesthetics. For example, the arrival of a new outfit may stir your creative juices in thinking about what shoes, jewelry and bag to pair it up with. This may certainly bring about a calmness in a way similar to art therapy, a well-known method of healing and reducing stress.&amp;nbsp;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;Some people treat shopping, both online and offline as a source of refreshment from the humdrum of daily life. Being a mindless activity, it enables people to relax and take some time off from their sources of stress. This form may vary from window shopping to scrolling on an online website or going to a shopping-mall for a break.&amp;nbsp;Yet another reason behind binge-purchasing may be the need to ‘feel connected’. For instance, one may shop for a sweater with a snowman or bells, candies and wreaths for decoration during Christmas, to feel more socially connected to the festival. Or someone may shop for a beret before visiting Paris to feel a part of the culture of the fashion capital. Thus, retail therapy may help individuals to feel closer to society and culture.&amp;nbsp;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;An extensive scrutiny of the idea suggests that the root cause lies in Sigmund Freud’s Pleasure Principle of psychology. The principle claims that individuals instinctively seek immediate pleasure to avoid experiencing feelings of stress, pain and sadness. In the context of impulsive purchasing, the principle fits well, as it is only a short term coping mechanism rooted in instant relief from stress. As compared to the Freudian Reality Principle, the Pleasure Principle is the &lt;a href=&quot;https://thepangean.com/Present-Bias-Focus-on-the-Now-but-maybe-Not-Always&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;inability of individuals to defer immediate gratification of certain desires and wants that rationality and reality may disallow.&amp;nbsp;&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;&lt;strong&gt;The Sadness Cycle&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;Even though retail therapy eases the anxiety and pain in people’s lives, such a positive impact may be short-lived. While retail therapy can be supported by psychological reasoning, Economics does not go hand-in-hand with the concept due to its assumption of rationality among all individuals. From the point of view of rationality, the problems of running out of budget and debts arise due to limited financial resources. Impulsive overspending may lead people to become even more anxious and distressed due to the inability of paying bills and lacking a sound financial base, in the long run. A rough patch after having run out of budget may seem more dramatic and difficult to handle, due to a lack of finance to purchase something to feel better. In desperate times like these, individuals addicted to the method, may resort to desperate measures like taking loans from others or stealing. This might be complemented with feelings of guilt due to unrealistically high expenditure patterns.&amp;nbsp;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;Thus, retail therapy, to an obsessive degree can lead to reverse effects by introducing a cycle of stress and anxiety for an individual rather than helping one fight the tough times.&amp;nbsp;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;&lt;strong&gt;The ‘Viral’ Remedy&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;With the Coronavirus pandemic hitting the world, people across the globe felt paralysed due to being restricted homes all the time. While this altered the work culture among people, the norms of schooling among students and put a halt to dining out, it had an impact on the shoppers. Research suggests that elements appealing to an individual’s senses, like aroma, music, a creative arrangement of products in a store, temperature contribute to the experience of shoppers. Unfortunately, with the lockdown implemented across the world, this ‘sensory’ experience was no longer available. As a result of this, one would expect sales to fall. However, the online retail industry led to a different turn of events.&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;According to &lt;em&gt;Forbes&lt;/em&gt;, as of March 2020, several online retail categories experienced a 74% year over year increase in sales, as compared to March 2018. Some of the top categories that saw a surge in the sale are home goods like furniture and home decor items and athletic and loungewear. While it may be argued that these categories resonate more with individuals in the current scenario due to the need to stay home, it must be noted that none of these items are essentials. Thus, it can be suggested that individuals binge purchased during the pandemic to escape the fears and stress of the situation and its uncertainty, thereby serving as a recent instance of retail therapy.&amp;nbsp;&lt;/p&gt;
&lt;p class=&quot;ql-align-justify&quot;&gt;The impact of retail therapy on an individual’s life depends upon the degree of engagement. On one hand, retail therapy in the form of window shopping, purchasing with adherence to one’s budget or buying pre-planned things can help to reduce stress and sadness both in the short term and long run. On the other hand, if the simple habit intensifies to become an addiction, it results in adverse problems which in turn brings more distress, thereby defeating the purpose of the ‘therapy’.&amp;nbsp;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Nirikta Mukherjee</name>
        
        
      </author>

      

      
        <category term="society" />
      

      
        <summary type="html">They say, “When the going gets tough, the tough go shopping.” This is more commonly known as Retail Therapy. It is a phenomenon where people shop to improve one’s disposition and raise spirits. People in distress often resort to this as a source of solace. A study published in the journal Psychology and Marketing states that retail therapy has a lasting positive effect on mood. While its findings pointed out that these are impulsive purchases, the survey suggested that feelings of guilt or regret were not associated among the respondents.&amp;nbsp;The name in itself is ironic. Shopping is a concept deeply rooted in materialism. As its positive impact is temporary, it does not qualify as a ‘therapy’ in the medical sense. However, it is a fairly popular phrase used around the world.&amp;nbsp; In a 2001 survey conducted by the European Union, it was found that 33% of the shoppers surveyed had a “high level of addiction to rash buying”. The study also revealed that ‘binge purchasing’ was most common among the Scottish youth. Another study of 1,000 American adults, conducted in 2013, detected that more than half of the respondents indulged in retail therapy. It also threw light on the gender aspect of the practice, stating that it is more common among women than men. It was found that 64.9% of women and 38.9% of men binge purchased while women mostly bought clothing, men indulged in ‘comfort food’. This was further reinforced by the Youngstown State University with similar male-female percentages, showing that relief from stress was the most common reason behind the practice. A more adverse extension of retail therapy is Oniomania or Compulsive Buying Disorder, which is an obsession with shopping, resulting in serious financial and mental consequences.&amp;nbsp; The Whys behind the Comfort Buys&amp;nbsp; While stress, anxiety and sadness are a part of daily life, they can be tackled through other means such as reaching out to others, practicing yoga, mindfulness and meditation, journaling, exercising and consulting experts in more severe cases. Despite there being these solutions, which on an average are cheaper than shopping, why do people indulge in purchasing things to boost their mood? To understand the causes behind retail therapy, the behavioral aspect of individuals needs to be analysed in a twofold manner. Even though, at first glance, these reasons seem simple — associated with daily life, a deeper analysis suggests that the root cause can be traced back to psychological theory.&amp;nbsp; Firstly, we examine the relatively straightforward causes.&amp;nbsp;&amp;nbsp;When everything goes wrong and nothing falls into place as you imagined it to, how do you feel? Out of control, right? Thus, one of the reasons people indulge in retail therapy is that shopping is a coping mechanism that helps people feel more in control. From deciding where to shop, to choosing what to purchase, it allows people to exercise autonomy and make decisions. In my personal opinion, shopping can also make one feel a sense of achievement. Utilising good offers and deals, applying coupons to get discounts and sometimes even getting goods for free certainly makes one feel happier as they ‘save’ along with fulfilling a guilty pleasure.&amp;nbsp; Secondly, retail therapy can be a useful mechanism for smooth transitions of life as it enables people to envisage their lives post such changes. For instance, people often shop excessively before they are going to live alone for the first time, shifting to a new house, getting married or having a baby. Shopping may ease anxiety by making people feel more in control by helping them to prepare themselves for such huge transitions through the process of ‘visualisation’, which is a process that boosts performance, confidence and reduces anxiety.&amp;nbsp; Another way in which retail therapy boosts mood is through a pleasant gush of creativity. Specifically, clothing of various kinds of colors and textures, accessories like jewelry, footwear, bags, sunglasses, etc, home decor items may induce a positive breeze of art and aesthetics. For example, the arrival of a new outfit may stir your creative juices in thinking about what shoes, jewelry and bag to pair it up with. This may certainly bring about a calmness in a way similar to art therapy, a well-known method of healing and reducing stress.&amp;nbsp; Some people treat shopping, both online and offline as a source of refreshment from the humdrum of daily life. Being a mindless activity, it enables people to relax and take some time off from their sources of stress. This form may vary from window shopping to scrolling on an online website or going to a shopping-mall for a break.&amp;nbsp;Yet another reason behind binge-purchasing may be the need to ‘feel connected’. For instance, one may shop for a sweater with a snowman or bells, candies and wreaths for decoration during Christmas, to feel more socially connected to the festival. Or someone may shop for a beret before visiting Paris to feel a part of the culture of the fashion capital. Thus, retail therapy may help individuals to feel closer to society and culture.&amp;nbsp; An extensive scrutiny of the idea suggests that the root cause lies in Sigmund Freud’s Pleasure Principle of psychology. The principle claims that individuals instinctively seek immediate pleasure to avoid experiencing feelings of stress, pain and sadness. In the context of impulsive purchasing, the principle fits well, as it is only a short term coping mechanism rooted in instant relief from stress. As compared to the Freudian Reality Principle, the Pleasure Principle is the inability of individuals to defer immediate gratification of certain desires and wants that rationality and reality may disallow.&amp;nbsp; The Sadness Cycle&amp;nbsp;&amp;nbsp; Even though retail therapy eases the anxiety and pain in people’s lives, such a positive impact may be short-lived. While retail therapy can be supported by psychological reasoning, Economics does not go hand-in-hand with the concept due to its assumption of rationality among all individuals. From the point of view of rationality, the problems of running out of budget and debts arise due to limited financial resources. Impulsive overspending may lead people to become even more anxious and distressed due to the inability of paying bills and lacking a sound financial base, in the long run. A rough patch after having run out of budget may seem more dramatic and difficult to handle, due to a lack of finance to purchase something to feel better. In desperate times like these, individuals addicted to the method, may resort to desperate measures like taking loans from others or stealing. This might be complemented with feelings of guilt due to unrealistically high expenditure patterns.&amp;nbsp; Thus, retail therapy, to an obsessive degree can lead to reverse effects by introducing a cycle of stress and anxiety for an individual rather than helping one fight the tough times.&amp;nbsp; The ‘Viral’ Remedy&amp;nbsp; With the Coronavirus pandemic hitting the world, people across the globe felt paralysed due to being restricted homes all the time. While this altered the work culture among people, the norms of schooling among students and put a halt to dining out, it had an impact on the shoppers. Research suggests that elements appealing to an individual’s senses, like aroma, music, a creative arrangement of products in a store, temperature contribute to the experience of shoppers. Unfortunately, with the lockdown implemented across the world, this ‘sensory’ experience was no longer available. As a result of this, one would expect sales to fall. However, the online retail industry led to a different turn of events. According to Forbes, as of March 2020, several online retail categories experienced a 74% year over year increase in sales, as compared to March 2018. Some of the top categories that saw a surge in the sale are home goods like furniture and home decor items and athletic and loungewear. While it may be argued that these categories resonate more with individuals in the current scenario due to the need to stay home, it must be noted that none of these items are essentials. Thus, it can be suggested that individuals binge purchased during the pandemic to escape the fears and stress of the situation and its uncertainty, thereby serving as a recent instance of retail therapy.&amp;nbsp; The impact of retail therapy on an individual’s life depends upon the degree of engagement. On one hand, retail therapy in the form of window shopping, purchasing with adherence to one’s budget or buying pre-planned things can help to reduce stress and sadness both in the short term and long run. On the other hand, if the simple habit intensifies to become an addiction, it results in adverse problems which in turn brings more distress, thereby defeating the purpose of the ‘therapy’.&amp;nbsp;</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Present Bias: Focus on the Now but maybe Not Always</title>
      <link href="/Present-Bias-Focus-on-the-Now-but-maybe-Not-Always" rel="alternate" type="text/html" title="Present Bias: Focus on the Now but maybe Not Always" />
      <published>2020-11-21T00:00:00+00:00</published>
      <updated>2020-11-21T00:00:00+00:00</updated>
      <id>/Present-Bias-Focus-on-the-Now-but-maybe-Not-Always</id>
      <content type="html" xml:base="/Present-Bias-Focus-on-the-Now-but-maybe-Not-Always">&lt;p&gt;Many times we wonder, what is it that makes us procrastinate? Why do we spend the whole day scrolling through Instagram instead of finishing the assignment that is due tomorrow? Apart from the fact that social media is designed to distract us, procrastinating isn't as simple as just being lazy. It isn't only about not wanting to do the task at hand, but more about how we humans are wired.&amp;nbsp; Procrastination is in fact related to a cognitive bias called the &lt;em&gt;present bias&lt;/em&gt;. As the name in itself suggests, it is the tendency of humans to be biased towards the present. This means that we tend to go for short-term rewards that provide us instant gratification rather than choosing long-term benefits. Thus, even though the benefit of finishing that assignment is clearly more than simply being on Instagram, the sense of gratification is achieved faster in the latter. Therefore, our brain might as well trick us into choosing the latter.&lt;/p&gt;
&lt;p&gt;It is important to understand why humans are actually biased towards the present. The answer lies in how our ancestors lived their lives. The times they lived in, it only made sense that they focused on the present. With the uncertainty of the future and the environment they lived in, they had no other option but to be short-sighted in their decision making. This present bias allowed them to survive and deal with the immediate threats that existed around them. Over the centuries, this outlook of theirs seems to have been so well engraved in our brains that even today we have a similar mindset. Despite us having a far more stable lifestyle and a future to actually look forward to, our brain still makes us biased towards our present. It still makes us believe that the future is a scary avenue that one shouldn't be focusing much on it.&lt;/p&gt;
&lt;p&gt;The idea of the present bias has been studied by many researchers over the years, in order to understand to what extent such a bias can affect the lives of individuals. An interesting experiment in this field was conducted by Walter Mischel. This experiment that goes by the name of &lt;em&gt;Marshmallow Test &lt;/em&gt;is a famous experiment which involved finding out whether children delayed gratification. It involved children being asked to either choose a marshmallow now or wait for 15-20 minutes to get two of them. This experiment, however, did not end here only. After a few years, these very children, who were by then adolescents, were traced and it was seen that the children who delayed gratification at a younger age were able to be more successful in the later period of their lives. Thus, shedding light on the connection between small decisions turning into a lifestyle.&lt;/p&gt;
&lt;p&gt;An interesting aspect of present bias is that it is not just limited to the field of psychology but also equally important for economics. Take for an example, if you were to choose between getting a job of ₹15,000/month now, or interning for free for a year and getting a job of ₹30,000/month. You are more likely to choose the former. But if you were asked to either complete your 3 years of Bachelor's and get a job starting at ₹15,000/month or to choose an integrated programme of 4 years that would allow you to get a package starting at ₹30,000/month, then you are most likely to choose the second option. Even though there isn’t a difference between these two cases other than the time periods, your choice would potentially differ. This is because our brain can only distinguish between the present and the future.&lt;/p&gt;
&lt;p&gt;Whether the future is three or four years down the lane, our brain fails to distinguish between them, because both are considered as far-sighted. Since our mind takes the future as uncertain it wants to make decisions for now, even though they might not be as beneficial. In economics, present bias is used when we talk about time inconsistency and discounting. Time inconsistency refers to the fact that individuals are inconsistent over time. That is, for instance, you decide to hit the gym next month, but when next month arrives, you are more likely to postpone it to another month. Thus, meaning that people aren't as rational in making decisions, but there are various social and psychological factors that govern their decisions. People have the tendency to change their choices, over different time periods even though the benefits remain the same. Richard H Thaler (a Nobel Prize Winner for his work in the field of behavioural economics) has conducted researches that show that economics and psychology are far more closely related than one can imagine, thus expanding the scope and importance of behavioural economics. He along with H M Shefrin wrote a paper titled &lt;em&gt;An Economic Theory of Self-control&lt;/em&gt; that introduced an economic model of self-control. This model explains that people aren't only lacking self-control when it comes to not buying new clothes, or when it comes to stopping with just another episode. But the lack of self-control can also be seen towards how people handle their finances, especially saving for their retirements before it gets late. To us, saving money seems more like a loss now even though it’ll benefit us in future, and thus people tend to postpone saving money. In fact, this research has led to various social policies to emerge to help people with saving their money from early days.&lt;/p&gt;
&lt;p&gt;Since it is wired into our system to focus on what could harm us immediately, rather than what could harm us in the long-term, present bias manifests itself in many of our actions. The concept of present bias explains why we humans tend to make self-harming choices that provide us instant gratification but clearly have harmful consequences in the future. It also explains why we tend to ignore the importance of climate change, since it doesn't seem like an instant harm to our minds.&lt;/p&gt;
&lt;p&gt;Living in the present is important, but it isn't all we should be focused on. In reality, our lives are a combination of the past, present and future and therefore it becomes equally important to realise that the present is only a small piece in the puzzle of life. Understanding what present bias is, and how strongly it can control our decision making, allows us to be more aware of our own selves. It makes us realise that our brains aren't always thinking what's best for us and can quite a few times make impulsive decisions that might not seem so right in the years to come. Clearly, our brains are guided by the fear of the future, because of all the uncertainty it brings. So it only makes sense that we continue to ignore the future, and be in a more comfortable zone, the present. And honestly, instant gratification, no matter for how little of a time, does feel good. But it also feels fulfilling to make decisions that'll help our future selves. This is the dilemma that present bias poses. Whether to choose the time that we know of or to choose the time that'll come. It isn't easy to break away from our habits, especially the ones that are so well engraved in our nerves. Self-control and will power aren't as easily attained as we are likely to believe. But what we can do is to be more aware of how our brains have a tendency of fooling our own selves, and maybe for once not trust whatever our brain has to say.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Priyanshi Mehra</name>
        
        
      </author>

      

      
        <category term="society" />
      

      
        <summary type="html">Many times we wonder, what is it that makes us procrastinate? Why do we spend the whole day scrolling through Instagram instead of finishing the assignment that is due tomorrow? Apart from the fact that social media is designed to distract us, procrastinating isn't as simple as just being lazy. It isn't only about not wanting to do the task at hand, but more about how we humans are wired.&amp;nbsp; Procrastination is in fact related to a cognitive bias called the present bias. As the name in itself suggests, it is the tendency of humans to be biased towards the present. This means that we tend to go for short-term rewards that provide us instant gratification rather than choosing long-term benefits. Thus, even though the benefit of finishing that assignment is clearly more than simply being on Instagram, the sense of gratification is achieved faster in the latter. Therefore, our brain might as well trick us into choosing the latter. It is important to understand why humans are actually biased towards the present. The answer lies in how our ancestors lived their lives. The times they lived in, it only made sense that they focused on the present. With the uncertainty of the future and the environment they lived in, they had no other option but to be short-sighted in their decision making. This present bias allowed them to survive and deal with the immediate threats that existed around them. Over the centuries, this outlook of theirs seems to have been so well engraved in our brains that even today we have a similar mindset. Despite us having a far more stable lifestyle and a future to actually look forward to, our brain still makes us biased towards our present. It still makes us believe that the future is a scary avenue that one shouldn't be focusing much on it. The idea of the present bias has been studied by many researchers over the years, in order to understand to what extent such a bias can affect the lives of individuals. An interesting experiment in this field was conducted by Walter Mischel. This experiment that goes by the name of Marshmallow Test is a famous experiment which involved finding out whether children delayed gratification. It involved children being asked to either choose a marshmallow now or wait for 15-20 minutes to get two of them. This experiment, however, did not end here only. After a few years, these very children, who were by then adolescents, were traced and it was seen that the children who delayed gratification at a younger age were able to be more successful in the later period of their lives. Thus, shedding light on the connection between small decisions turning into a lifestyle. An interesting aspect of present bias is that it is not just limited to the field of psychology but also equally important for economics. Take for an example, if you were to choose between getting a job of ₹15,000/month now, or interning for free for a year and getting a job of ₹30,000/month. You are more likely to choose the former. But if you were asked to either complete your 3 years of Bachelor's and get a job starting at ₹15,000/month or to choose an integrated programme of 4 years that would allow you to get a package starting at ₹30,000/month, then you are most likely to choose the second option. Even though there isn’t a difference between these two cases other than the time periods, your choice would potentially differ. This is because our brain can only distinguish between the present and the future. Whether the future is three or four years down the lane, our brain fails to distinguish between them, because both are considered as far-sighted. Since our mind takes the future as uncertain it wants to make decisions for now, even though they might not be as beneficial. In economics, present bias is used when we talk about time inconsistency and discounting. Time inconsistency refers to the fact that individuals are inconsistent over time. That is, for instance, you decide to hit the gym next month, but when next month arrives, you are more likely to postpone it to another month. Thus, meaning that people aren't as rational in making decisions, but there are various social and psychological factors that govern their decisions. People have the tendency to change their choices, over different time periods even though the benefits remain the same. Richard H Thaler (a Nobel Prize Winner for his work in the field of behavioural economics) has conducted researches that show that economics and psychology are far more closely related than one can imagine, thus expanding the scope and importance of behavioural economics. He along with H M Shefrin wrote a paper titled An Economic Theory of Self-control that introduced an economic model of self-control. This model explains that people aren't only lacking self-control when it comes to not buying new clothes, or when it comes to stopping with just another episode. But the lack of self-control can also be seen towards how people handle their finances, especially saving for their retirements before it gets late. To us, saving money seems more like a loss now even though it’ll benefit us in future, and thus people tend to postpone saving money. In fact, this research has led to various social policies to emerge to help people with saving their money from early days. Since it is wired into our system to focus on what could harm us immediately, rather than what could harm us in the long-term, present bias manifests itself in many of our actions. The concept of present bias explains why we humans tend to make self-harming choices that provide us instant gratification but clearly have harmful consequences in the future. It also explains why we tend to ignore the importance of climate change, since it doesn't seem like an instant harm to our minds. Living in the present is important, but it isn't all we should be focused on. In reality, our lives are a combination of the past, present and future and therefore it becomes equally important to realise that the present is only a small piece in the puzzle of life. Understanding what present bias is, and how strongly it can control our decision making, allows us to be more aware of our own selves. It makes us realise that our brains aren't always thinking what's best for us and can quite a few times make impulsive decisions that might not seem so right in the years to come. Clearly, our brains are guided by the fear of the future, because of all the uncertainty it brings. So it only makes sense that we continue to ignore the future, and be in a more comfortable zone, the present. And honestly, instant gratification, no matter for how little of a time, does feel good. But it also feels fulfilling to make decisions that'll help our future selves. This is the dilemma that present bias poses. Whether to choose the time that we know of or to choose the time that'll come. It isn't easy to break away from our habits, especially the ones that are so well engraved in our nerves. Self-control and will power aren't as easily attained as we are likely to believe. But what we can do is to be more aware of how our brains have a tendency of fooling our own selves, and maybe for once not trust whatever our brain has to say.</summary>
      

      
      
    </entry>
  
</feed>
